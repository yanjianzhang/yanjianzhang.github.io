<!DOCTYPE html><html class="appearance-auto" lang="en"><head><meta name="google-site-verification" content="EnW3iE5uXnkCt08dH5N1p2UztpHHWUslmyE_mIIGaac"><meta name="baidu-site-verification" content="code-EtTckMomHC"><meta charset="UTF-8"><title>Yanjian Zhang's blog</title><meta name="description" content="精诚致志，求仁存心"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/favicon.png"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/widget-post-list.css"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.0.0"><link rel="alternate" href="/atom.xml" title="Yanjian Zhang's Blog" type="application/atom+xml">
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">Yanjian Zhang's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><span>Archives · All</span></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></header><main><article class="post-container is-flex is-justify-content-center section container is-max-widescreen pt-4 px-2"><div class="columns is-variable is-1-tablet is-3-desktop-only is-2-widescreen is-full-width"><section class="column"><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Programming"><i class="tag post-item-tag">Programming</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2022/09/16/recursive_20220916/">Pre-order traversal and Recursive</a></h2><time class="has-text-grey" datetime="2022-09-15T22:00:00.000Z">2022-09-16</time><p class="is-flex-grow-2 mt-2">今天重新回顾了深度优先搜索和递归，突然发现递归过程可以看成是对于程序数的先序遍历,中序遍历和后序遍历比方说以下例子
def DFS()
    print(1)        # node itself
    DFS()           # left tree
    DFS()           # right tree

以上例子就可以看成先序遍历的二叉树
def DFS()
    DFS()           # left tree
    print(1)        # node itself
    DFS()           # right tree

以上例子就可以看成中序遍历的二叉树
同理还可以有多叉树等等，用这样的思路思考递归运算的程序复杂度就可以参考遍历树的复杂度来求..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2022/09/16/recursive_20220916/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Conda"><i class="tag post-item-tag">Conda</i></a><a href="/tags/Jupyter%20notebook"><i class="tag post-item-tag">Jupyter notebook</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2021/02/19/ipykernel/">conda, pip, jupyter</a></h2><time class="has-text-grey" datetime="2021-02-18T23:00:00.000Z">2021-02-19</time><p class="is-flex-grow-2 mt-2">Conda 环境配置
conda create --name &amp;lt;env_name&amp;gt; &amp;lt;package_name&amp;gt;
conda create --name tf python=3.6
source activate tf

Conda 环境中安装 jupyter notebook 内核
conda install nb_conda
pip install ipykernel
python -m ipykernel install --user --name tf --display-name tf

pip 在 Mac Conda环境中 会出现与当前python不一致情况，使用
python -m pip install package_name

而不是
pip install pa..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2021/02/19/ipykernel/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Natural%20Language%20Processing"><i class="tag post-item-tag">Natural Language Processing</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2020/02/19/NLP_toolkit/">常见NLP工具包</a></h2><time class="has-text-grey" datetime="2020-02-18T23:00:00.000Z">2020-02-19</time><p class="is-flex-grow-2 mt-2">FudanNLP (FNLP)Github 地址
主要是为中文自然语言处理而开发的工具包，也包含为实现这些任务的机器学习算法和数据集。
fastNLPGithub 地址
中文的NLP工具包，提供多种神经网络组件以及复现模型（涵盖中文分词、命名实体识别、句法分析、文本分类、文本匹配、指代消解、摘要等任务）;
Stanford CoreNLP主页地址是基于java的程序包，提供一系列 jar 包用于命名实体识别(NER)、共指消解(Coreference)、依赖分析
StanfordNLPGithub 地址
主要用于词法特征标记和依赖项解析，比如词性标注(POS)，词元分析（Lemma）, 依赖分析（dependency relation）
Pytorch-NLPGithub 地址
个人比较文本预处理工具包，可..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2020/02/19/NLP_toolkit/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Natural%20Language%20Processing"><i class="tag post-item-tag">Natural Language Processing</i></a><a href="/tags/Reinforcement%20Learning"><i class="tag post-item-tag">Reinforcement Learning</i></a><a href="/tags/Adversarial%20Learning"><i class="tag post-item-tag">Adversarial Learning</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2020/02/11/RLSeq2Seq/">NLG里的强化与对抗</a></h2><time class="has-text-grey" datetime="2020-02-10T23:00:00.000Z">2020-02-11</time><p class="is-flex-grow-2 mt-2">本篇讲述三篇论文
《SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient》
《Adversarial learning for neural dialogue generation》
《Deep Reinforcement Learning for Sequence-to-Sequence Models》
对于文本生成来说一般会有编码器(可以来源于文本，图像和图网络信息)，还会有解码器
解码器的loss往往是使用每个词的NLL(negative log likelihood)来获得，而这意味着一旦进行了解码，就没有办法对整句话进行评价了。因此为了解决这个问题，往往使用强化学习的方法。
SeqGANs就使用了强化学习的方法来实现反向..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2020/02/11/RLSeq2Seq/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Reinforcement%20Learning"><i class="tag post-item-tag">Reinforcement Learning</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2019/12/29/RL/">强化学习精要总结（基础）</a></h2><time class="has-text-grey" datetime="2019-12-28T23:00:00.000Z">2019-12-29</time><p class="is-flex-grow-2 mt-2">本博文假设基本的状态表示和动作表示都已经了解的情况下，对多个强化学习方法进行简要对比
阅读长篇英文博文请点击这里
Major division: Value iteration and Policy iteration
1. Value IterationDynamic Programming: when the model is fully known, it can be directly solved by Dynamic Programming.
When the model is not solve, we need reinforcement learning.
值迭代就是顺着动态规划的思路，只要我们将值估计出来，就能够进行规划了。
Generalized Policy Iteration (G..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2019/12/29/RL/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/P.h.D."><i class="tag post-item-tag">P.h.D.</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2019/12/27/doctor/">Top essays by scientists in 2019</a></h2><time class="has-text-grey" datetime="2019-12-26T23:00:00.000Z">2019-12-27</time><p class="is-flex-grow-2 mt-2">Source Link
Ashley Stenzel’s essay about the joys and challenges of raising two daughters while working toward a Ph.D. struck a chord with readers. “Good to know I’m not alone in this struggle. The guilt can be horrible,” one reader wrote on Science’s Facebook page earlier this month. “I loved every word of the story. As a graduate student with a child I c..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2019/12/27/doctor/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/AI"><i class="tag post-item-tag">AI</i></a><a href="/tags/Commonsense"><i class="tag post-item-tag">Commonsense</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2019/12/21/Commonsence/">Commonsense Validation and Explanation</a></h2><time class="has-text-grey" datetime="2019-12-20T23:00:00.000Z">2019-12-21</time><p class="is-flex-grow-2 mt-2">本文主要关注SemEval-2020常识验证与解释部分
Task4: Commonsense Validation and Explanation (常识验证和解释)Subtask1 Commonsense Validation给出两句有相似结构的陈述，任务就是检验哪句陈述相对符合常识，哪句不符合常识。E.g. (A: He put a turkey into the fridge) vs.(B: He put an elephant into the fridge). 正确答案：A相对符合，B相对不符合。分析：这一个题目
Subtask2 Commonsense Explanation (Multi-Choice)从subtask1承接而来。给出不符合常识陈述的标签，并给出三个候选原因，选择出最能够解释不..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2019/12/21/Commonsence/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/RNN"><i class="tag post-item-tag">RNN</i></a><a href="/tags/Dropout"><i class="tag post-item-tag">Dropout</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2019/12/04/encoder-decoder/">Dropout of RNN, batch size, accumulation steps</a></h2><time class="has-text-grey" datetime="2019-12-03T23:00:00.000Z">2019-12-04</time><p class="is-flex-grow-2 mt-2">DropoutSrivastava et al. (2014) applied dropout to feed forward neural network’s and RBM’s and noted a probability of dropout around 0.5 for hidden units and 0.2 for inputs worked well for a variety of tasks.
Reference: A review of Dropout as applied to RNNs
When I apply the 0.5 for hidden units and 0.2 for inputs, it works well. But it is not the case in ..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2019/12/04/encoder-decoder/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Python"><i class="tag post-item-tag">Python</i></a><a href="/tags/Latex"><i class="tag post-item-tag">Latex</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2019/12/04/indent/">Indent problem! Latex and Python</a></h2><time class="has-text-grey" datetime="2019-12-03T23:00:00.000Z">2019-12-04</time><p class="is-flex-grow-2 mt-2">PythonWhen we cooperation with other within python, like in Cloud studio of tencent. We may find our indent is different with our friend when we input the code. You may make a file name  “.editorconfig” in the root directory.
root = true

[*]
charset = utf-8
indent_style = tab
tab_width = 4
end_of_line = lf
insert_final_newline = true
trim_trailing_whitesp..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2019/12/04/indent/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Matlab"><i class="tag post-item-tag">Matlab</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2018/11/15/Matlab/">Matlab的使用笔记</a></h2><time class="has-text-grey" datetime="2018-11-14T23:44:02.000Z">2018-11-15</time><p class="is-flex-grow-2 mt-2">变量显示变量的值disp(x)
矩阵矩阵的生成方式,既可以用空格也可以用逗号来隔开元素A = [1 2 3 4]多行的向量的矩阵使用分号隔开A = [1 2 3; 4 5 6; 7 8 10]ones、zeros 或 rand 等函数生成列向量z = zeros(5,1)
矩阵的转置使用单引号’A’标准矩阵乘法Ainv(A)元素级乘法.元素级运算.^3,.3,./3
Matlab优先处理矩阵的列，如下幻方矩阵A = [16 3 2 13; 5 10 11 8; 9 6 7 12; 4 15 14 1]sum(A),为列相加得到的行向量结果为：ans =    34    34    34    34
数组横向串联A = [A,A]纵向串联A = [A;A]复数i = sqrt(-1),可以直接写作i
文本和..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2018/11/15/Matlab/">Read more</a></section></article><section class="paginator is-flex is-justify-content-flex-end is-flex-wrap-wrap mt-5"><span class="page-number current">1</span><a class="page-number" href="/archives/page/2/">2</a><a class="page-number" href="/archives/page/3/">3</a><a class="extend next" rel="next" href="/archives/page/2/"><i class="iconfont icon-next has-text-grey"></i></a></section></section><aside class="column is-hidden-mobile is-4-tablet is-3-widescreen"><div style="position: sticky; top: 50px;"><main class="aside-card-container archives-widget is-in-archive-page"><h3>Archives</h3><section><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/09/">September 2022</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/02/">February 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a><span class="archive-list-count">8</span></li></ul></section></main></div></aside></div></article><script>$claudia.fadeInImage(null, $claudia.blurBackdropImg)

window.addEventListener('resize', $claudia.throttle(function () {
    var images = document.querySelectorAll('.js-img-fadeIn')

    images.forEach($claudia.blurBackdropImg)
}, 150))</script></main><script>$claudia.fadeInImage(null, $claudia.blurBackdropImg)

window.addEventListener('resize', $claudia.throttle(function () {
    var images = document.querySelectorAll('.js-img-fadeIn')

    images.forEach($claudia.blurBackdropImg)
}, 150))</script></body></html>