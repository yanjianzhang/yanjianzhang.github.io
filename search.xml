<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Pre-order traversal and Recursive</title>
      <link href="/2022/09/16/recursive_20220916/"/>
      <url>/2022/09/16/recursive_20220916/</url>
      
        <content type="html"><![CDATA[<p>今天重新回顾了深度优先搜索和递归，<br>突然发现递归过程可以看成是对于程序数的先序遍历,中序遍历和后序遍历<br>比方说以下例子</p><pre><code class="lang-python">def DFS()    print(1)        # node itself    DFS()           # left tree    DFS()           # right tree</code></pre><p>以上例子就可以看成先序遍历的二叉树</p><pre><code class="lang-python">def DFS()    DFS()           # left tree    print(1)        # node itself    DFS()           # right tree</code></pre><p>以上例子就可以看成中序遍历的二叉树</p><p>同理还可以有多叉树等等，用这样的思路思考递归运算的程序复杂度就可以参考遍历树的复杂度来求解了</p>]]></content>
      
      
      <categories>
          
          <category> Programming </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Programming </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>conda, pip, jupyter</title>
      <link href="/2021/02/19/ipykernel/"/>
      <url>/2021/02/19/ipykernel/</url>
      
        <content type="html"><![CDATA[<p>Conda 环境配置</p><pre><code class="lang-shell">conda create --name &lt;env_name&gt; &lt;package_name&gt;conda create --name tf python=3.6source activate tf</code></pre><p>Conda 环境中安装 jupyter notebook 内核</p><pre><code class="lang-shell">conda install nb_condapip install ipykernelpython -m ipykernel install --user --name tf --display-name tf</code></pre><p>pip 在 Mac Conda环境中 会出现与当前python不一致情况，使用</p><pre><code class="lang-shell">python -m pip install package_name</code></pre><p>而不是</p><pre><code class="lang-shell">pip install package_name</code></pre>]]></content>
      
      
      <categories>
          
          <category> environment </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Jupyter notebook </tag>
            
            <tag> Conda </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>常见NLP工具包</title>
      <link href="/2020/02/19/NLP_toolkit/"/>
      <url>/2020/02/19/NLP_toolkit/</url>
      
        <content type="html"><![CDATA[<h4 id="FudanNLP-FNLP"><a href="#FudanNLP-FNLP" class="headerlink" title="FudanNLP (FNLP)"></a>FudanNLP (FNLP)</h4><p><a href="https://github.com/FudanNLP/fnlp">Github 地址</a></p><p>主要是为中文自然语言处理而开发的工具包，也包含为实现这些任务的机器学习算法和数据集。</p><h4 id="fastNLP"><a href="#fastNLP" class="headerlink" title="fastNLP"></a>fastNLP</h4><p><a href="https://github.com/fastnlp/fastNLP">Github 地址</a></p><p>中文的NLP工具包，提供多种神经网络组件以及复现模型（涵盖中文分词、命名实体识别、句法分析、文本分类、文本匹配、指代消解、摘要等任务）;</p><h4 id="Stanford-CoreNLP"><a href="#Stanford-CoreNLP" class="headerlink" title="Stanford CoreNLP"></a>Stanford CoreNLP</h4><p><a href="https://github.com/pytorch/fairseq">主页地址</a><br>是基于java的程序包，提供一系列 jar 包用于命名实体识别(NER)、共指消解(Coreference)、依赖分析</p><h4 id="StanfordNLP"><a href="#StanfordNLP" class="headerlink" title="StanfordNLP"></a>StanfordNLP</h4><p><a href="https://github.com/stanfordnlp/stanfordnlp">Github 地址</a></p><p>主要用于词法特征标记和依赖项解析，比如词性标注(POS)，词元分析（Lemma）, 依赖分析（dependency relation）</p><h4 id="Pytorch-NLP"><a href="#Pytorch-NLP" class="headerlink" title="Pytorch-NLP"></a>Pytorch-NLP</h4><p><a href="https://github.com/PetrochukM/PyTorch-NLP">Github 地址</a></p><p>个人比较文本预处理工具包，可以很快将自己的新数据集转化为可以用于训练的batch，引入词向量也很方便。</p><h4 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h4><p><a href="https://github.com/huggingface/transformers">Github 地址</a> </p><p>能够直接展示自动补全的writing是其一大特色, 可见他们的<a href="https://transformer.huggingface.co/">Online demo</a></p><h3 id="Neural-machine-translation"><a href="#Neural-machine-translation" class="headerlink" title="Neural machine translation"></a>Neural machine translation</h3><h4 id="OpenNMT"><a href="#OpenNMT" class="headerlink" title="OpenNMT"></a>OpenNMT</h4><p><a href="https://github.com/OpenNMT/OpenNMT-py">Github pytorch 地址</a>  <a href="https://github.com/OpenNMT/OpenNMT-tf">Github tensorflow 地址</a></p><p>个人感觉非常好用，不过pytorch的版本需要pytorch1.12，非CUDA 9.2以上的版本需要自己编译pytorch。</p><p>pytorch文档中直接提供了Seq2Seq以及transformer的直接使用方法【<a href="http://opennmt.net/OpenNMT-py/extended.html">Seq2Seq</a> <a href="http://opennmt.net/OpenNMT-py/FAQ.html#how-do-i-use-the-transformer-model">Transformer</a>】，同时还提供Image2Text，Speech2Text以及Video2Text的使用方法</p><p>tensorflow的使用方法也很直接。</p><h4 id="FairSeq"><a href="#FairSeq" class="headerlink" title="FairSeq"></a>FairSeq</h4><p><a href="https://github.com/pytorch/fairseq">Github 地址</a></p><p>Facebook AI Research 专门为 Torch定制的翻译模型，后面也开源了pytorch版本</p><p>基于卷积神经网络的翻译模型首先是Facebook提出来的，所以在这个工具包里面是满满的卷积网络</p><h4 id="UniLM"><a href="#UniLM" class="headerlink" title="UniLM"></a>UniLM</h4><p><a href="https://github.com/microsoft/unilm">Github 地址</a></p><p>当前最强的seq-to-seq的语言模型</p>]]></content>
      
      
      <categories>
          
          <category> Natural Language Processing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Natural Language Processing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NLG里的强化与对抗</title>
      <link href="/2020/02/11/RLSeq2Seq/"/>
      <url>/2020/02/11/RLSeq2Seq/</url>
      
        <content type="html"><![CDATA[<p>本篇讲述三篇论文</p><p>《SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient》</p><p>《Adversarial learning for neural dialogue generation》</p><p>《Deep Reinforcement Learning for Sequence-to-Sequence Models》</p><p>对于文本生成来说一般会有编码器(可以来源于文本，图像和图网络信息)，还会有解码器</p><p>解码器的loss往往是使用每个词的NLL(negative log likelihood)来获得，而这意味着一旦进行了解码，就没有办法对整句话进行评价了。因此为了解决这个问题，往往使用强化学习的方法。</p><p>SeqGANs就使用了强化学习的方法来实现反向传播。中间为了使得生成完整的句子用于Discriminator能够衡量reward，还使用了蒙特卡洛的方法。之所以使用MCTS这主要受限于问题的假设，是没有编码器的文本生成，一开始的生成序列会非常短。这意味着就是生成的结果基本取决于训练的文本，就像是图像中的的人脸数据集就会生成人脸，而油画数据集就会生成油画一样。</p><p>对于我来说，最难的部分就在于如何在代码中计算loss，我在SeqGANs的代码中看到这样一段</p><pre><code class="lang-python">def batchPGLoss(self, inp, target, reward):        &quot;&quot;&quot;        Returns a pseudo-loss that gives corresponding policy gradients (on calling .backward()).        Inspired by the example in http://karpathy.github.io/2016/05/31/rl/        Inputs: inp, target            - inp: batch_size x seq_len            - target: batch_size x seq_len            - reward: batch_size (discriminator reward for each sentence, applied to each token of the corresponding                      sentence)            inp should be target with &lt;s&gt; (start letter) prepended        &quot;&quot;&quot;        batch_size, seq_len = inp.size()        inp = inp.permute(1, 0)          # seq_len x batch_size        target = target.permute(1, 0)    # seq_len x batch_size        h = self.init_hidden(batch_size)        loss = 0        for i in range(seq_len):            out, h = self.forward(inp[i], h)            # TODO: should h be detached from graph (.detach())?            for j in range(batch_size):                loss += -out[j][target.data[i][j]]*reward[j]     # log(P(y_t|Y_1:Y_&#123;t-1&#125;)) * Q        return loss/batch_size</code></pre><p>访问代码中的博客<a href="http://karpathy.github.io/2016/05/31/rl/，">http://karpathy.github.io/2016/05/31/rl/，</a> 我确实被惊艳了，作者正好说了我最需要关注的东西，监督学习与强化学习的比较，我确实不敢相信它是如此的2016 (just joking)。</p><p>不过蒙特卡洛除了解决这一个问题之外，还解决了一个Reward for Every Generation Step(REGS)的问题，以下是从<a href="https://www.cnblogs.com/n2meetu/p/8182194.html">其他博文</a>中找到的描述</p><p>‘’在以往的工作中，D效果非常好而G的效果非常糟糕会带来训练效果的下降。试想一下一个G所有产生的答案都被D驳回了，在这段时间内G的所有反馈都是负反馈，G就会迷失从而不知道向什么方向优化会得到正反馈，所以理想的情况下G和D是交替训练上升的。’’</p><p>《Adversarial learning for neural dialogue generation》正是注意到了这一点，对其使用部分片段的评价进行优化。</p><p>之后的内容待以后再更新….</p>]]></content>
      
      
      <categories>
          
          <category> Reinforcement Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Natural Language Processing </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Adversarial Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>强化学习精要总结（基础）</title>
      <link href="/2019/12/29/RL/"/>
      <url>/2019/12/29/RL/</url>
      
        <content type="html"><![CDATA[<p>本博文假设基本的状态表示和动作表示都已经了解的情况下，对多个强化学习方法进行简要对比</p><p>阅读长篇英文博文请<a href="https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html">点击这里</a></p><p>以下内容增加了自己的一些补充，不仅仅是上文的概述</p><p>Major division: <strong>Value iteration</strong> and <strong>Policy iteration</strong></p><h3 id="Generalized-Policy-Iteration-GPI"><a href="#Generalized-Policy-Iteration-GPI" class="headerlink" title="Generalized Policy Iteration (GPI)"></a>Generalized Policy Iteration (GPI)</h3><p>$V_{t+1}(s)=\mathbb{E}_{\pi}\left[r+\gamma V_{t}\left(s^{\prime}\right) | S_{t}=s\right]=\sum_{a} \pi(a | s) \sum_{s^{\prime}, r} P\left(s^{\prime}, r | s, a\right)\left(r+\gamma V_{k}\left(s^{\prime}\right)\right)$</p><p>$Q_{\pi}(s, a)=\mathbb{E}\left[R_{t+1}+\gamma V_{\pi}\left(S_{t+1}\right) | S_{t}=s, A_{t}=a\right]=\sum_{s^{\prime}, r} P\left(s^{\prime}, r | s, a\right)\left(r+\gamma V_{\pi}\left(s^{\prime}\right)\right)$</p><h3 id="DP-methods"><a href="#DP-methods" class="headerlink" title="DP methods"></a>DP methods</h3><p>Dynamic Programming: when the model is fully known, it can be directly solved by Dynamic Programming.</p><p>值迭代就是顺着动态规划的思路，只要我们将值估计出来，就能够进行规划了。</p><p>策略分为两步:<br>Policy evalutation: Estimate $v^\pi$<br>Policy improvement: Generate $\pi^{new} &gt;  \pi$</p><p>Value iteration 是 policy iteration的一种特殊情况，此时policy evaluation 只做一步，而policy iteration是迭代到最优</p><h3 id="Sample-backups-Methods"><a href="#Sample-backups-Methods" class="headerlink" title="Sample backups Methods"></a>Sample backups Methods</h3><p>传统的DP解法：full-width backups<br>新方法：sample backups， 使用样本的平均值而不是模型预期回报<br>优势： model free, break curse of dimensionality</p><h4 id="Monte-Carlo"><a href="#Monte-Carlo" class="headerlink" title="Monte-Carlo"></a>Monte-Carlo</h4><p>使用采样出来的轨迹模拟上述公式<br>$V(s)=\frac{\sum_{t=1}^{T} 1\left[S_{t}=s\right] G_{t}}{\sum_{t=1}^{T} 1\left[S_{t}=s\right]}$     $Q(s, a)=\frac{\sum_{t=1}^{T} 1\left[S_{t}=s, A_{t}=a\right] G_{t}}{\sum_{t=1}^{T} 1\left[S_{t}=s, A_{t}=a\right]}$</p><h4 id="1-Value-Iteration"><a href="#1-Value-Iteration" class="headerlink" title="1. Value Iteration"></a>1. Value Iteration</h4><h5 id="Temporal-Difference-Learning"><a href="#Temporal-Difference-Learning" class="headerlink" title="Temporal-Difference Learning:"></a>Temporal-Difference Learning:</h5><p>估计量改为 $R_{t+1}+\gamma V\left(S_{t+1}\right)$，即可得到<br>$V\left(S_{t}\right) \leftarrow V\left(S_{t}\right)+\alpha\left(R_{t+1}+\gamma V\left(S_{t+1}\right)-V\left(S_{t}\right)\right)$<br>$Q\left(S_{t}, A_{t}\right) \leftarrow Q\left(S_{t}, A_{t}\right)+\alpha\left(R_{t+1}+\gamma Q\left(S_{t+1}, A_{t+1}\right)-Q\left(S_{t}, A_{t}\right)\right)$</p><p>比较三种方法<br>| 方法  |  boostrap  | biase | variance| backup |<br>|—-|—-|—-|—-| —-|<br>| DP  |   no  | —- | —-| full, shallow<br>| MC  |   yes  | no | huge| with sample, deep<br>| TD  |   yes |yes| small| with sample, shallow</p><p>以下的方法皆为TD Learning的拓展：</p><h5 id="SARSA-On-Policy-TD-control"><a href="#SARSA-On-Policy-TD-control" class="headerlink" title="SARSA: On-Policy TD control"></a>SARSA: On-Policy TD control</h5><p>使用$\varepsilon$ -greedy来获得动作，从而得到两次动作（行动策略$a, s_t$ 和 评估策略$a’,s_{t+1}’$）<br>$Q\left(S_{t}, A_{t}\right) \leftarrow Q\left(S_{t}, A_{t}\right)+\alpha\left(R_{t+1}+\gamma Q\left(S_{t+1}, A_{t+1}\right)-Q\left(S_{t}, A_{t}\right)\right)$</p><h5 id="Q-Learning-Off-policy-TD-control"><a href="#Q-Learning-Off-policy-TD-control" class="headerlink" title="Q-Learning: Off-policy TD control"></a>Q-Learning: Off-policy TD control</h5><p>Off-policy 是指行动策略和评估策略不同，Q-learning的评估策略是贪婪的，公式对比极易看出<br>$Q\left(S_{t}, A_{t}\right) \leftarrow Q\left(S_{t}, A_{t}\right)+\alpha\left(R_{t+1}+\gamma \max _{a \in \mathcal{A}} Q\left(S_{t+1}, a\right)-Q\left(S_{t}, A_{t}\right)\right)_{-}$</p><h4 id="2-Policy-Iteration"><a href="#2-Policy-Iteration" class="headerlink" title="2. Policy Iteration"></a>2. Policy Iteration</h4><p>Policy Iteration 完全是另一种解决方案，是去优化策略值函数的期望</p><p>$\mathcal{J}(\theta)=\sum_{s \in \mathcal{S}} d_{\pi_{\theta}}(s) V_{\pi_{\theta}}(s)=\sum_{s \in \mathcal{S}}\left(d_{\pi_{\theta}}(s) \sum_{a \in \mathcal{A}} \pi(a | s, \theta) Q_{\pi}(s, a)\right)$</p><p>求梯度，并转化为$\pi_{\theta}$下的期望</p><p>$\nabla \mathcal{J}(\theta)=\mathbb{E}_{\pi_{\theta}}\left[\nabla \ln \pi(a | s, \theta) Q_{\pi}(s, a)\right]$</p><p>剩下的就是梯度更新的问题了</p><h4 id="REINFORCE"><a href="#REINFORCE" class="headerlink" title="REINFORCE"></a>REINFORCE</h4><p>使用蒙特卡洛的方法获得一系列轨迹，使用$A(s, a)=Q(s, a)-V(s)$来进行梯度更新<br>$\theta \leftarrow \theta+\alpha \gamma^{t} G_{t} \nabla \ln \pi\left(A_{t} | S_{t}, \theta\right)$</p><h3 id="3-Actor-Critic：结合两部分"><a href="#3-Actor-Critic：结合两部分" class="headerlink" title="3. Actor-Critic：结合两部分"></a>3. Actor-Critic：结合两部分</h3><p>既更新策略期望，又更新值函数<br>$\theta \leftarrow \theta+\alpha_{\theta} Q(s, a ; w) \nabla_{\theta} \ln \pi(a | s ; \theta)$<br>$w \leftarrow w+\alpha_{w} G_{t: t+1} \nabla_{w} Q(s, a ; w)$</p><h4 id="Asynchronous-Advantage-Actor-Critic-A3C"><a href="#Asynchronous-Advantage-Actor-Critic-A3C" class="headerlink" title="Asynchronous Advantage Actor-Critic (A3C)"></a>Asynchronous Advantage Actor-Critic (A3C)</h4><p>异步：多线程 优势：使用优势函数进行更新<br>$d \theta \leftarrow d \theta+\nabla_{\theta^{\prime}} \log \pi\left(a_{i} | s_{i} ; \theta^{\prime}\right)\left(R-V\left(s_{i} ; w^{\prime}\right)\right)$<br>$d w \leftarrow d w+\nabla_{w^{\prime}}\left(R-V\left(s_{i} ; w^{\prime}\right)\right)^{2}$<br>异步获得梯度，进行加和，同步更新</p>]]></content>
      
      
      <categories>
          
          <category> Reinforcement Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Top essays by scientists in 2019</title>
      <link href="/2019/12/27/doctor/"/>
      <url>/2019/12/27/doctor/</url>
      
        <content type="html"><![CDATA[<p><a href="https://www.sciencemag.org/careers/2019/12/our-top-essays-scientists-2019">Source Link</a></p><p>Ashley Stenzel’s essay about the joys and challenges of raising two daughters while working toward a Ph.D. struck a chord with readers. “Good to know I’m not alone in this struggle. The guilt can be horrible,” one reader wrote on Science’s Facebook page earlier this month. “I loved every word of the story. As a graduate student with a child I can totally relate,” wrote another.<br>Stenzel’s piece was one of 51 essays we published this year as part of our ongoing Working Life series, which shines a spotlight on personal and professional challenges that scientists face as they pursue their careers. As the year draws to a close, we put together a list of our 10 most popular essays of 2019. Read on to find out about a disastrous postdoc experience, an eye-opening trip abroad, unexpected career transitions, and more.</p><ol><li><a href="https://www.sciencemag.org/careers/2019/10/why-scientists-should-take-more-coffee-breaks">Why scientists should take more coffee breaks</a><br>Vivienne Tam argued that it’s important for grad students to make time for casual conversations with peers.</li><li><a href="https://www.sciencemag.org/careers/2019/06/how-i-learned-teach-scientist">How I learned to teach like a scientist</a><br>Sally Hoskins reflected on how she challenged students to think beyond the facts during her career as a college professor.</li><li><a href="https://www.sciencemag.org/careers/2019/07/committee-members-shouldn-t-expect-phd-students-serve-coffee-and-pastries">Committee members shouldn’t expect Ph.D. students to serve coffee and pastries</a><br>Kate Bredbenner wrote that thesis defenses and committee meetings are stressful enough without the added expectation of bringing food.</li><li><a href="https://www.sciencemag.org/careers/2019/10/reviewers-don-t-be-rude-nonnative-english-speakers">Reviewers, don’t be rude to nonnative English speakers</a><br>Adriana Romero-Olivares offered three principles for providing constructive, respectful feedback during the peer-review process.</li><li><a href="https://www.sciencemag.org/careers/2019/01/my-first-postdoc-position-was-disaster-what-i-learned">My first postdoc position was a disaster. This is what I learned</a><br>Victor Wong wrote that he should have quit his first postdoc and moved on much sooner.</li><li><a href="https://www.sciencemag.org/careers/2019/04/academia-hard-work-expected-taking-break-effort-well-spent-too">In academia, hard work is expected—but taking a break is effort well spent, too</a><br>Mattias Björnmalm reflected on why it’s important to take time away from work.</li><li><a href="https://www.sciencemag.org/careers/2019/04/academia-hard-work-expected-taking-break-effort-well-spent-too">How I became easy prey to a predatory publisher</a><br>Alan Chambers recounted how an email and the pressure to publish led him astray.</li><li><a href="https://www.sciencemag.org/careers/2019/02/reimbursement-policies-make-academia-less-inclusive">Reimbursement policies make academia less inclusive</a><br>Jessica Sagers argued that having to pay conference expenses up front from personal accounts is a significant burden for early-career researchers.</li><li><a href="https://www.sciencemag.org/careers/2019/02/leaving-phd-takes-courage-and-it-doesn-t-mean-path-academic-success-over">Leaving a Ph.D. takes courage—and it doesn’t mean the path to academic success is over</a><br>Hendrik Huthoff wrote that leaving his first Ph.D. program was one of the most important professional decisions he ever made.</li><li><a href="https://www.sciencemag.org/careers/2019/12/how-i-let-go-my-guilt-mother-grad-school">How I let go of my guilt as a mother in grad school</a><br>Ashley Stenzel realized that her daughters have benefited from her pursuit of higher education.<h3 id="Honorable-mentions"><a href="#Honorable-mentions" class="headerlink" title="Honorable mentions:"></a>Honorable mentions:</h3><a href="https://www.sciencemag.org/careers/2019/08/how-i-conquered-my-fear-public-speaking-and-learned-give-effective-presentations">How I conquered my fear of public speaking and learned to give effective presentations</a><br><a href="https://www.sciencemag.org/careers/2018/07/its-never-too-late-stretch-your-wings-why-i-got-phd-age-66">It’s never too late to stretch your wings: Why I got a Ph.D. at age 66</a><br><a href="https://www.sciencemag.org/careers/2018/07/its-never-too-late-stretch-your-wings-why-i-got-phd-age-66">Three lessons from industry that I’m taking back to academia</a><br><a href="https://www.sciencemag.org/careers/2019/05/i-felt-lost-new-academic-culture-then-i-learned-about-hidden-curriculum">I felt lost in a new academic culture. Then I learned about the hidden curriculum</a><br><a href="https://www.sciencemag.org/careers/2019/10/post-phd-job-searches-are-tough-here-s-how-i-escaped-dr-seuss-s-waiting-place">Post-Ph.D. job searches are tough. Here’s how I escaped Dr. Seuss’s ‘Waiting Place’</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> P.h.D. career </category>
          
      </categories>
      
      
        <tags>
            
            <tag> P.h.D. </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Commonsense Validation and Explanation</title>
      <link href="/2019/12/21/Commonsence/"/>
      <url>/2019/12/21/Commonsence/</url>
      
        <content type="html"><![CDATA[<p>本文主要关注<a href="http://alt.qcri.org/semeval2020/index.php?id=tasks">SemEval-2020</a>常识验证与解释部分</p><h3 id="Task4-Commonsense-Validation-and-Explanation-常识验证和解释"><a href="#Task4-Commonsense-Validation-and-Explanation-常识验证和解释" class="headerlink" title="Task4: Commonsense Validation and Explanation (常识验证和解释)"></a>Task4: Commonsense Validation and Explanation (常识验证和解释)</h3><h4 id="Subtask1-Commonsense-Validation"><a href="#Subtask1-Commonsense-Validation" class="headerlink" title="Subtask1 Commonsense Validation"></a>Subtask1 Commonsense Validation</h4><p>给出两句有相似结构的陈述，任务就是检验哪句陈述相对符合常识，哪句不符合常识。E.g. (A: He put a turkey into the fridge) vs.(B: He put an elephant into the fridge). 正确答案：A相对符合，B相对不符合。<br>分析：这一个题目</p><h4 id="Subtask2-Commonsense-Explanation-Multi-Choice"><a href="#Subtask2-Commonsense-Explanation-Multi-Choice" class="headerlink" title="Subtask2 Commonsense Explanation (Multi-Choice)"></a>Subtask2 Commonsense Explanation (Multi-Choice)</h4><p>从subtask1承接而来。给出不符合常识陈述的标签，并给出三个候选原因，选择出最能够解释不符合常识那个陈述出错的原因。E.g.不符合常识的陈述：(He put an elephant into the fridge) 三个候选原因：(A: an elephant is much bigger than a fridge), (B: elephants are usually gray while fridges are usually white), and (C: an elephant cannot eat a fridge)。正确答案:A.</p><h4 id="Subtask3-Commonsense-Explanation-Generation"><a href="#Subtask3-Commonsense-Explanation-Generation" class="headerlink" title="Subtask3 Commonsense Explanation(Generation)"></a>Subtask3 Commonsense Explanation(Generation)</h4><p> 也从subtask1承接而来。给出不符合常识的陈述，并要求生成解释其不符合常识的原因。训练集、开发集和测试集中每个例子都会提供三条正确原因，以供训练、开发和测试。比赛中结果以BLEU值来衡量，最终结果会以人工评价的方法衡量。E.g.不符合常识的陈述：(He put an elephant into the fridge) 三条正确原因：(A: an elephant is much bigger than a fridge), (B: a fridge is much smaller than an elephant), and (C: an elephant cannot fit in a fridge)。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>与传统的NLI任务文本蕴含关系识别相比，文本蕴含识别中的contradiction, neutral, entailment是两个句子之间的矛盾，然而仅仅知道它们是矛盾的并不能得出他们的对错。<br>在这里的Commonsense Validation中，两个句子固然是矛盾的，这一点并没有办法用于选出哪个合理。<br>在Explanation中，陈述和回答里虽然确实有contradiction的意思，然而却需要额外的常识才能选出答案。</p><h4 id="与CommonsenseQA相比较"><a href="#与CommonsenseQA相比较" class="headerlink" title="与CommonsenseQA相比较"></a>与CommonsenseQA相比较</h4><p>CommonsenseQA还是存在相关的选项的文本经常与题干同时出现的问题的文本关联性的影响，可以说解决了CommonsenseQA的问题还不一定能够解决Commonsense Explanation的问题，而Commonsense Validation还是能够通过相似的方法解决的。</p>]]></content>
      
      
      <categories>
          
          <category> Natural Language Processing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> Commonsense </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dropout of RNN, batch size, accumulation steps</title>
      <link href="/2019/12/04/encoder-decoder/"/>
      <url>/2019/12/04/encoder-decoder/</url>
      
        <content type="html"><![CDATA[<h3 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h3><p>Srivastava et al. (2014) applied dropout to feed forward neural network’s and RBM’s and noted a probability of dropout around <strong>0.5 for hidden units and 0.2 for inputs</strong> worked well for a variety of tasks.</p><p>Reference: <a href="https://medium.com/@bingobee01/a-review-of-dropout-as-applied-to-rnns-72e79ecd5b7b">A review of Dropout as applied to RNNs</a></p><p>When I apply the 0.5 for hidden units and 0.2 for inputs, it works well. But it is not the case in decoder. <strong>In decoder, I would suggest not to use dropout</strong>.</p><h3 id="Batch-Size"><a href="#Batch-Size" class="headerlink" title="Batch Size"></a>Batch Size</h3><p>Suggest &lt;=32， See <a href="https://www.cs.cmu.edu/~muli/file/minibatch_sgd.pdf">Efficient Mini-batch Training for Stochastic Optimization</a> and <a href="https://svail.github.io/rnn_perf/">this RNN study</a></p><h3 id="Accumulation-steps"><a href="#Accumulation-steps" class="headerlink" title="Accumulation_steps"></a>Accumulation_steps</h3><p>Have the same function like batch size, but it can be use when Graphics memory is not enough.</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RNN </tag>
            
            <tag> Dropout </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Indent problem! Latex and Python</title>
      <link href="/2019/12/04/indent/"/>
      <url>/2019/12/04/indent/</url>
      
        <content type="html"><![CDATA[<h3 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h3><p>When we cooperation with other within python, like in <a href="https://studio.dev.tencent.com/">Cloud studio</a> of tencent. We may find our indent is different with our friend when we input the code. You may make a file name  “.editorconfig” in the root directory.</p><pre><code>root = true[*]charset = utf-8indent_style = tabtab_width = 4end_of_line = lfinsert_final_newline = truetrim_trailing_whitespace = true</code></pre><p>However, when the python code are already mixed with tabs and spaces. Don’t worry.<br>Select Pycharm -&gt; Edit -&gt; Convert Indents. You will transform the whole file quickly without manually do it.</p><h3 id="Matlab"><a href="#Matlab" class="headerlink" title="Matlab"></a>Matlab</h3><p>When you copy the code to texstudio(seems not happend in Overleaf), the indent will vanish. It is the problem of default setting of Texstudio.<br>Select Options -&gt; Configure Texstudio -&gt; Editor -&gt; Indentation mode. And choose Keep Indentation.<br>That will solve the problem.</p><p>&nbsp; &nbsp;<br>&nbsp; &nbsp;<br>&nbsp; &nbsp;</p><h5 id="Reference-Version-in-Chinese-from-Google-translation"><a href="#Reference-Version-in-Chinese-from-Google-translation" class="headerlink" title="Reference Version in Chinese from Google translation:"></a>Reference Version in Chinese from Google translation:</h5><h3 id="Python-1"><a href="#Python-1" class="headerlink" title="Python"></a>Python</h3><p>当我们在python中与其他人合作时，例如腾讯的[Cloud studio]（<a href="https://studio.dev.tencent.com/）。">https://studio.dev.tencent.com/）。</a> 输入代码时，我们可能会发现缩进与我们的朋友有所不同。 您可以在根目录创建一个文件名“ .editorconfig”。</p><pre><code>根=真[*]字符集= utf-8indent_style =制表符tab_width = 4end_of_line = lfinsert_final_newline = truetrim_trailing_whitespace = true</code></pre><p>但是，当python代码已经与制表符和空格混合在一起时。 不用担心<br>选择Pycharm-&gt;编辑-&gt;转换缩进。 您无需手动进行操作即可快速转换整个文件。</p><h3 id="Matlab-1"><a href="#Matlab-1" class="headerlink" title="Matlab"></a>Matlab</h3><p>当您将代码复制到texstudio时（似乎在Overleaf中没有发生），缩进将消失。 这是Texstudio默认设置的问题。<br>选择选项-&gt;配置Texstudio-&gt;编辑器-&gt;缩进模式。 然后选择“保持缩进”。<br>这样可以解决问题。</p>]]></content>
      
      
      <categories>
          
          <category> Latex </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Latex </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Matlab的使用笔记</title>
      <link href="/2018/11/15/Matlab/"/>
      <url>/2018/11/15/Matlab/</url>
      
        <content type="html"><![CDATA[<h3 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h3><p>显示变量的值<br>disp(x)</p><h3 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h3><p>矩阵的生成方式,既可以用空格也可以用逗号来隔开元素<br>A = [1 2 3 4]<br>多行的向量的矩阵使用分号隔开<br>A = [1 2 3; 4 5 6; 7 8 10]<br>ones、zeros 或 rand 等函数生成列向量<br>z = zeros(5,1)</p><p>矩阵的转置使用单引号’<br>A’<br>标准矩阵乘法<em><br>A</em>inv(A)<br>元素级乘法<br>.<em><br>元素级运算<br>.^3,.</em>3,./3</p><p>Matlab优先处理矩阵的列，如下幻方矩阵<br>A = [16 3 2 13; 5 10 11 8; 9 6 7 12; 4 15 14 1]<br>sum(A),为列相加得到的行向量<br>结果为：ans =<br>    34    34    34    34</p><h3 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h3><p>横向串联<br>A = [A,A]<br>纵向串联<br>A = [A;A]<br>复数i = sqrt(-1),可以直接写作i</p><h3 id="文本和字符串"><a href="#文本和字符串" class="headerlink" title="文本和字符串"></a>文本和字符串</h3><p>文本使用单引号表示<br>myText = ‘Hello, world’;<br>字符串中的单引号需要使用两个单引号表示<br>otherText = ‘You’’re right’<br>方括号串联字符数组，就像串联数值数组一样<br>longText = [myText,’ - ‘,otherText]</p><h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><p>如果存在多个输出参数，请将其括在方括号中</p><p>[maxA,location] = max(A)<br>clc 函数清除命令行窗口</p><h3 id="二维图和三维图"><a href="#二维图和三维图" class="headerlink" title="二维图和三维图"></a>二维图和三维图</h3><p><a href="https://ww2.mathworks.cn/help/matlab/learn_matlab/plots.html">链接</a></p><h3 id="构建表"><a href="#构建表" class="headerlink" title="构建表"></a>构建表</h3><p>使用列向量构建表<br>n = (0:9)’;<br>pows = [n  n.^2  2.^n]<br>结果为<br>pows =<br>     0     0     1<br>     1     1     2<br>     2     4     4<br>     3     9     8<br>     4    16    16<br>     5    25    32<br>     6    36    64<br>     7    49   128<br>     8    64   256<br>     9    81   512</p><h3 id="逻辑下标"><a href="#逻辑下标" class="headerlink" title="逻辑下标"></a>逻辑下标</h3><p>相当于找到数组中满足条件的部分，例如<br>x = [2.1 1.7 1.6 1.5 NaN 1.9 1.8 1.5 5.1 1.8 1.4 2.2 1.6 1.8];<br>x = x(isfinite(x))<br>结果为<br>x =<br>  2.1 1.7 1.6 1.5 1.9 1.8 1.5 5.1 1.8 1.4 2.2 1.6 1.8</p><h3 id="find函数"><a href="#find函数" class="headerlink" title="find函数"></a>find函数</h3><p>find 函数可用于确定与指定逻辑条件相符的数组元素的索引。<br>find 以最简单的形式返回索引的列向量。转置该向量以便获取索引的行向量。<br>如幻方矩阵<br>k = find(isprime(A))’<br>结果为<br>k =<br>     2     5     9    10    11    13<br>运行<br>A(k) = NaN<br>结果为<br>A =<br>    16   NaN   NaN   NaN<br>   NaN    10   NaN     8<br>     9     6   NaN    12<br>     4    15    14     1</p><h3 id="元胞数组"><a href="#元胞数组" class="headerlink" title="元胞数组"></a>元胞数组</h3><p>使用{}生成，使用三维数组可以存储相同大小的矩阵序列。元胞数组可用于存储不同大小的矩阵序列<br>*要操作包含不同长度的行的文本主体，您有两种选择，即使用填充的字符数组或使用字符向量元胞数组。创建字符数组时，数组各行的长度必须相同。（使用空格填充较短行的末尾。）char 函数可执行这种填充操作。例如，<br>S = char(‘A’,’rolling’,’stone’,’gathers’,’momentum.’)<br>生成一个 5×9 字符数组：<br>S =<br>A<br>rolling<br>stone<br>gathers<br>momentum.<br>再者，也可以将文本存储在元胞数组中。例如，<br>C = {‘A’;’rolling’;’stone’;’gathers’;’momentum.’}</p><h3 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a>结构体</h3><p>使用struct(“key”,”value”,”key”,”value”)生成<br>引用方法<br>S.score<br>S(2).name = ‘Toni Miller’;</p><h3 id="Matlab绘图"><a href="#Matlab绘图" class="headerlink" title="Matlab绘图"></a>Matlab绘图</h3><p><a href="https://ww2.mathworks.cn/help/matlab/learn_matlab/data-analysis.html">链接</a></p>]]></content>
      
      
      <categories>
          
          <category> Matlab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Matlab </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习评价指标</title>
      <link href="/2018/11/09/measure/"/>
      <url>/2018/11/09/measure/</url>
      
        <content type="html"><![CDATA[<h4 id="分类问题的评价指标"><a href="#分类问题的评价指标" class="headerlink" title="分类问题的评价指标"></a>分类问题的评价指标</h4><div class="table-container"><table><thead><tr><th>*</th><th>Relevant，正类</th><th>Nonrelevent，负类</th></tr></thead><tbody><tr><td>Retrieved 被检索到</td><td>TP</td><td>FP</td></tr><tr><td>Notretrieved未检索到</td><td>FN</td><td>TN</td></tr></tbody></table></div><p>准确率是：对于给定的测试数据集，分类器正确分类的样本数与总样本数之比</p><script type="math/tex; mode=display">A(accurate) = \frac{TP+TN}{TP+TN+FP+FN}</script><p>精确率是：它计算的是所有被检索到的item中,”应该被检索到”的item占的比例。</p><script type="math/tex; mode=display">P(percision) = \frac{TP}{TP+FP}</script><p>召回率是：它计算的是所有检索到的item占所有”应该检索到的item”的比例。</p><script type="math/tex; mode=display">R(recall) = \frac{TP}{TP+FN}</script><p>综合评价指标F-measure是精确度和召回率的综合</p><script type="math/tex; mode=display">F = \frac{(a^2+1)PR}{(a^2)P+R}</script><p>当a = 0时，为F1:</p><script type="math/tex; mode=display">F = \frac{PR}{P+R}</script><h4 id="机器翻译质量评测算法"><a href="#机器翻译质量评测算法" class="headerlink" title="机器翻译质量评测算法"></a>机器翻译质量评测算法</h4><p>使用BLEU来衡量算法的准确程度<br>计算公式如下</p><script type="math/tex; mode=display">BLEU = BP·exp(\sum_1^N w_nlog(p_n))</script><p>其中BP = $\begin{cases}1\space\space\space\space\space\space\space\space\space\space\space\space\space\space if \space c&gt;r \\e^{(1-r/c)}\space\space\space\space if \space c \le r\end{cases}<br>$<br>c = len(word of machine)<br>r = len(word of reference)<br>而 <script type="math/tex">p_n = \frac{\sum_{C\in Candidate}\sum_{n-gram\in C}Count_{clip}(n-gram)}{\sum_{C^{'}\in Candidate}\sum_{n-gram\in C'}Count_(n-gram)}</script></p>]]></content>
      
      
      <categories>
          
          <category> Machine Learing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tensorboard的使用</title>
      <link href="/2018/11/09/tensorboard/"/>
      <url>/2018/11/09/tensorboard/</url>
      
        <content type="html"><![CDATA[<p>其中<br>summary.image生成新的图像用于验证输入结果的准确与否<br>summary.scalar用于记录准确率、损失等信息<br>得到的结果需要进行 merged = tf.summary.merge_all()<br>最后要sess.run([train_step,merged])</p><pre><code class="lang-python">import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_datamax_steps = 1000learning_rate = 0.001dropout = 0.9data_dir = &quot;&quot;log_dir = &quot;C:/Users/dongfanker/Desktop/log&quot;mnist = input_data.read_data_sets(data_dir, one_hot=True)sess = tf.InteractiveSession()with tf.name_scope(&quot;input&quot;):    x = tf.placeholder(tf.float32, [None, 784], name=&quot;x-input&quot;)    y_ = tf.placeholder(tf.float32, [None, 10], name=&quot;y-input&quot;)with tf.name_scope(&quot;input_reshape&quot;):    image_shaped_input = tf.reshape(x, [-1, 28, 28, 1])    tf.summary.image(&quot;input&quot;, image_shaped_input, 10)# 创建初始化参数的方法def weight_variable(shape):    initial = tf.truncated_normal(shape, stddev=0.1)    return tf.Variable(initial)def bias_variable(shape):    initial = tf.constant(0.1, shape=shape)    return tf.Variable(initial)def variable_summaries(var):    with tf.name_scope(&quot;summaries&quot;):        mean = tf.reduce_mean(var)        tf.summary.scalar(&quot;mean&quot;, mean)        with tf.name_scope(&quot;stddev&quot;):            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))        tf.summary.scalar(&quot;stddev&quot;, stddev)    tf.summary.scalar(&quot;stddev&quot;, stddev)    tf.summary.scalar(&quot;max&quot;, tf.reduce_max(var))    tf.summary.scalar(&quot;min&quot;, tf.reduce_min(var))    tf.summary.histogram(&quot;histogram&quot;, var)def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):    with tf.name_scope(layer_name):        with tf.name_scope(&quot;weights&quot;):            weights = weight_variable([input_dim, output_dim])            variable_summaries(weights)        with tf.name_scope(&quot;biases&quot;):            biases = bias_variable([output_dim])            variable_summaries(biases)        with tf.name_scope(&quot;linear_compute&quot;):            preactivate = tf.matmul(input_tensor, weights) + biases            tf.summary.histogram(&quot;pre_activation&quot;, preactivate)        activations = act(preactivate, name=&quot;activation&quot;)        tf.summary.histogram(&quot;activation&quot;, activations)        return activationshidden1 = nn_layer(x, 784, 500, &quot;layer1&quot;)with tf.name_scope(&quot;dropout&quot;):    keep_prob = tf.placeholder(tf.float32)    tf.summary.scalar(&quot;dropout_keep_probability&quot;, keep_prob)    dropped = tf.nn.dropout(hidden1, keep_prob)y = nn_layer(dropped, 500, 10, &quot;layer2&quot;, act=tf.identity)with tf.name_scope(&quot;cross_entropy&quot;):    diff = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y)    with tf.name_scope(&quot;total&quot;):        cross_entropy = tf.reduce_mean(diff)tf.summary.scalar(&quot;loss&quot;, cross_entropy)with tf.name_scope(&quot;train&quot;):    train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)with tf.name_scope(&quot;accuracy&quot;):    with tf.name_scope(&quot;correct_prediction&quot;):        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))    with tf.name_scope(&quot;accuracy&quot;):        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))tf.summary.scalar(&quot;accuracy&quot;, accuracy)merged = tf.summary.merge_all()train_writer = tf.summary.FileWriter(log_dir + &quot;/train&quot;, sess.graph)test_writer = tf.summary.FileWriter(log_dir + &quot;/test&quot;)tf.global_variables_initializer().run()def feed_dict(train):    if train:        xs, ys = mnist.train.next_batch(100)        k = dropout    else:        xs, ys = mnist.test.images, mnist.test.labels        k = 1.0    return &#123;x: xs, y_: ys, keep_prob: k&#125;saver = tf.train.Saver()for i in range(max_steps):    if i % 10 == 0:        summary, acc = sess.run([merged, accuracy], feed_dict=feed_dict(False))        test_writer.add_summary(summary, i)        print(&quot;Accuracy at step %s: %s&quot; % (i, acc))    else:        if i % 100 == 99:            run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)            run_metadata = tf.RunMetadata()            summary, _ = sess.run([merged, train_step],                                  feed_dict=feed_dict(True),                                  options=run_options,                                  run_metadata=run_metadata)            train_writer.add_run_metadata(run_metadata, &quot;step%03d&quot; % i)            train_writer.add_summary(summary, i)            saver.save(sess, log_dir + &quot;/model.ckpt&quot;, i)            print(&quot;Adding run metadata for &quot;, i)        else:            summary, _ = sess.run([merged, train_step],                                  feed_dict=feed_dict(True))            train_writer.add_summary(summary, i)train_writer.close()test_writer.close()</code></pre>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tensorflow </tag>
            
            <tag> tensorboard </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tensorflow 基本概念</title>
      <link href="/2018/11/08/tfbase/"/>
      <url>/2018/11/08/tfbase/</url>
      
        <content type="html"><![CDATA[<h4 id="计算图"><a href="#计算图" class="headerlink" title="计算图"></a>计算图</h4><p>Tensorflow程序的计算可分为两个阶段，在第一个阶段定义所有计算图中的计算，第二阶段为执行计算。<br>下面定义一个计算，生成计算图</p><pre><code class="lang-python">import tensorflow as tfa = tf.constant([1.0, 2.0], name=&quot;a&quot;)b = tf.constant([2.0, 3.0], name=&quot;b&quot;)result = a + b print(tf.get_default_graph())print(a.graph)print(b.graph)</code></pre><p>result: 均属于同一个计算图</p><pre><code>&lt;tensorflow.python.framework.ops.Graph object at 0x0000012C137DAD68&gt;&lt;tensorflow.python.framework.ops.Graph object at 0x0000012C137DAD68&gt;&lt;tensorflow.python.framework.ops.Graph object at 0x0000012C137DAD68&gt;</code></pre><p>还可以通过tf.Graph函数来生成新的计算图，代码如下，注意注释的部分已经被淘汰</p><pre><code class="lang-python">import tensorflow as tfg1 = tf.Graph()with g1.as_default():    v1 = tf.get_variable(        # &quot;v&quot;, initializer=tf.zeros_initializer(shape[1])        &quot;v1&quot;, shape=[4], initializer=tf.zeros_initializer()    )    v2 = tf.get_variable(        &quot;v2&quot;, shape=[4], initializer=tf.ones_initializer()    )with tf.Session(graph=g1) as sess:    # # tf.initialize_all_variables().run()    sess.run(tf.global_variables_initializer())    with tf.variable_scope(&quot;&quot;, reuse=True):        print(sess.run(tf.get_variable(&quot;v1&quot;)))        print(sess.run(tf.get_variable(&quot;v2&quot;)))</code></pre><p>result</p><pre><code>[ 0.  0.  0.  0.][ 1.  1.  1.  1.]</code></pre><h4 id="张量"><a href="#张量" class="headerlink" title="张量"></a>张量</h4><p>下面介绍张量</p><pre><code class="lang-python">import tensorflow as tfa = tf.constant([1, 2], name=&quot;a&quot;, dtype=tf.float32)b = tf.constant([2.0, 3.0], name=&quot;b&quot;)result1 = a + b# 此时还没有结果print(result1)result2 = tf.add(a, b, name=&quot;add&quot;)# 此时才会有结果print(result2)</code></pre><p>result：可以看见在result1中默认会命名“+”为add，后面相同的名字TensorFlow会进行修改</p><pre><code>Tensor(&quot;add:0&quot;, shape=(2,), dtype=float32)Tensor(&quot;add_1:0&quot;, shape=(2,), dtype=float32)</code></pre><h4 id="会话"><a href="#会话" class="headerlink" title="会话"></a>会话</h4><p>下面是会话<br>创建会话可以通过两种模式创建，一种是明确创建和关闭会话的函数</p><pre><code class="lang-python">sess = tf.Session()sess.run(...)sess.close()</code></pre><p>另一种就直接通过上下文管理器来管理会话，使用with</p><pre><code class="lang-python">with tf.Session() as sess:    sess.run(...)</code></pre><p>配置GPU的使用,其中allow_soft_placement会使得某些不被GPU支持的运算放入CPU中，而log_device_placement选择是否打印日记，可以记录那个节点被安排到哪个设备方便调试，而在生产环境中设为False,可以减少日志量</p><pre><code>config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)with tf.Session(graph=g1, config=config) as sess:    ......</code></pre><h4 id="前向传播示例"><a href="#前向传播示例" class="headerlink" title="前向传播示例"></a>前向传播示例</h4><p>下面是一个简单的神经网络的前向传播的过程,注意x为列向量，有两个[]</p><pre><code class="lang-python">import tensorflow as tfw1 = tf.Variable(tf.random_normal([2, 3], stddev=1, seed=1))w2 = tf.Variable(tf.random_normal([3, 1], stddev=1, seed=1))print(w1, w2)x = tf.constant([[0.7, 0.9]])a = tf.matmul(x, w1)y = tf.matmul(a, w2) #此处是product# 也可以是 with tf.Session as sess:sess = tf.Session()# 此处需要进行初始化sess.run(tf.global_variables_initializer()) # 获得所想要得到的运算结果print(sess.run(y)) #对product进行运算sess.close()</code></pre><p>result</p><pre><code>[[ 3.95757794]]</code></pre><h4 id="placeholder"><a href="#placeholder" class="headerlink" title="placeholder"></a>placeholder</h4><pre><code class="lang-python">input1 = tf.placeholder(tf.float32)</code></pre><p>之后需要feed才能run</p><h4 id="添加层"><a href="#添加层" class="headerlink" title="添加层"></a>添加层</h4><pre><code class="lang-python">def add_layer(inputs,in_size,out_size,activation_fun = None):    weight = tf.VAriable(tf.random_normal([in_size,out_size]))    biase = ...    if activation != None:        return activation(input*weight+biase)</code></pre><h4 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h4><pre><code class="lang-python"># None 表示任意数量xs = tf.placeholder(tf.float32,[None, 784]) # 28*28ys = tf.placeholder(tf.float32,[None, 10]) # 10</code></pre><h4 id="构建网络"><a href="#构建网络" class="headerlink" title="构建网络"></a>构建网络</h4><pre><code>l1 = add_layer(xs, 1, 10 activation = tf.nn.relu)loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys-prediction),reduction_indices = [1]))train_step = tf.train.Gradient...sess.run(...)</code></pre><h4 id="GPU-support"><a href="#GPU-support" class="headerlink" title="GPU support"></a>GPU support</h4><pre><code class="lang-python">config = tf.ConfigProto()config.gpu_options.allow_growth = True # 按需分配，不全部占用for d in [&quot;/device:GPU:2&quot;,&quot;/device:GPU:3&quot;] #使用多块GPU    with tf.device(d):</code></pre>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tensorflow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>字符串和文本处理</title>
      <link href="/2018/11/07/cookbookString/"/>
      <url>/2018/11/07/cookbookString/</url>
      
        <content type="html"><![CDATA[<h4 id="字符串的切分"><a href="#字符串的切分" class="headerlink" title="字符串的切分"></a>字符串的切分</h4><pre><code class="lang-python">line = &quot;爸爸 妈妈; 儿子, 女儿,弟弟, 妹妹&quot;import reprint(re.split(r&#39;[;,\s]\s*&#39;, line))print(re.split(r&#39;(;|,|\s)\s*&#39;, line))fields = re.split(r&#39;(;|,|\s)\s*&#39;, line)print(fields[::2])print(fields[1::2])</code></pre><p>result:</p><pre><code>[&#39;爸爸&#39;, &#39;妈妈&#39;, &#39;儿子&#39;, &#39;女儿&#39;, &#39;弟弟&#39;, &#39;妹妹&#39;][&#39;爸爸&#39;, &#39; &#39;, &#39;妈妈&#39;, &#39;;&#39;, &#39;儿子&#39;, &#39;,&#39;, &#39;女儿&#39;, &#39;,&#39;, &#39;弟弟&#39;, &#39;,&#39;, &#39;妹妹&#39;][&#39;爸爸&#39;, &#39;妈妈&#39;, &#39;儿子&#39;, &#39;女儿&#39;, &#39;弟弟&#39;, &#39;妹妹&#39;][&#39; &#39;, &#39;;&#39;, &#39;,&#39;, &#39;,&#39;, &#39;,&#39;]</code></pre><p>总结: “\s” 代表空格，一定范围的符号用[]、(…|…|…)框起来，使用[]会去掉匹配的文本，而(…|…|…)会保留匹配的分组，可变长(0-n)的字段可以加*l，在末尾的field的切片中，最后一位代表step</p><h4 id="字符串的开头与结尾匹配"><a href="#字符串的开头与结尾匹配" class="headerlink" title="字符串的开头与结尾匹配"></a>字符串的开头与结尾匹配</h4><pre><code class="lang-python">filenames = [&quot;Makefile&quot;, &quot;foo.c&quot;, &quot;bar.py&quot;, &quot;spam.c&quot;, &quot;spam.h&quot;]print(any(name.endswith(&quot;.py&quot;) for name in filenames))print([name for name in filenames if name.endswith((&quot;.c&quot;, &quot;.h&quot;))])</code></pre><p>result</p><pre><code>True[&#39;foo.c&#39;, &#39;spam.c&#39;, &#39;spam.h&#39;]</code></pre><p>总结：直接使用str.startswith()，str.endswith()，any用于检验列表元素的有无，两个函数可以作为判断指标生成新的列表，注意这两个函数内部如果有多个匹配的话需要用tuple(元组)把它们括起来<br>也可以使用match来进行开头的匹配，代码如下</p><pre><code class="lang-python">import reurl = &quot;http://www.python.org&quot;res = re.match(&quot;https|http|ftp&quot;, url)print(res != None)print(res.group())</code></pre><p>result</p><pre><code>Truehttp</code></pre><h4 id="字符串的匹配与搜索"><a href="#字符串的匹配与搜索" class="headerlink" title="字符串的匹配与搜索"></a>字符串的匹配与搜索</h4><pre><code class="lang-python">import retext = &quot;Today is 11/27/2012. PyCon starts 3/13/2013&quot;print(text.find(&quot;PyCon&quot;))print(re.findall(r&#39;\d+/\d+/\d+&#39;, text))datapat = re.compile(r&#39;\d+/\d+/\d+&#39;)print(datapat.findall(text))</code></pre><p>result</p><pre><code>21[&#39;11/27/2012&#39;, &#39;3/13/2013&#39;][&#39;11/27/2012&#39;, &#39;3/13/2013&#39;]</code></pre><p>find可以返回第一个匹配的位置，如果想要找到所有的匹配，可以使用findall，一方面可以直接使用，另一方面可以将模式字符串预编译为模式对象</p>]]></content>
      
      
      <categories>
          
          <category> Natural Language Processing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> string process </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Good-Turing、Absolute、kneser-ney smooth</title>
      <link href="/2018/11/04/kneser-ney/"/>
      <url>/2018/11/04/kneser-ney/</url>
      
        <content type="html"><![CDATA[<h3 id="Good-Turing-smoothing"><a href="#Good-Turing-smoothing" class="headerlink" title="Good-Turing smoothing"></a>Good-Turing smoothing</h3><p>Good-Turing基本思想是：用观察计数较高的N元语法数重新估计概率量的大小，并把它指派给那些具有零计数或者较低计数的N元语法。<br>公式:</p><script type="math/tex; mode=display">c^{×} = \frac{(c+1)N_{c+1}}{N_c}</script><p>其中c为某个N-gram出现的频数, $N_c$ 为出现次数为c的N-Gram的词组的个数，$c^×$为Good-Turing平滑计数<br>例子:对于a = [A,A,A,B,B,C,D,E] sum(len(a)) = 7<br>$c_A = 3$    $c_C = 2$</p><p>$c_B = c_D = c_E = 1$</p><p>$N_1=4$ $N_2=1$ $N_3=1$ </p><p>thus </p><script type="math/tex; mode=display">c^{×} = 4 × \frac{0}{3} = 0</script><script type="math/tex; mode=display">c^×_B = 3×\frac{1}{1} = 3</script><script type="math/tex; mode=display">c^×_C = c^×_D = c^×_E = 2×\frac{1}{4} = \frac{1}{2}</script><p>（注意在他们求概率的时候都需要除以N = 7）<br>然而这样会导致最高频率的结果最后的计数为0，解决方法如下</p><ol><li>可以对于较低的计数使用$P_{GT}$,而对于较高的计数直接使用$P_{MLE} = \frac{c}{N}$</li><li>也可以在较大的计数的时候使用$F(r) = ar^b $,其中a，b为参数，b&lt;-1</li></ol><p>最终会出现概率之和不为0的情况，这时候要进行归一化，固定没有见过的结果的概率，将已经见过的概率之和归一化使得共同的概率结果为1<br>归一化例子可见于<a href="https://www.csd.uwo.ca/courses/CS4442b/L9-NLP-LangModels.pdf">L9-NLP-LangModels.pdf</a>第64页</p><h3 id="Absolute-discounting"><a href="#Absolute-discounting" class="headerlink" title="Absolute discounting"></a>Absolute discounting</h3><p>一般的interpolation是利用高阶的模型的$P_MLE$乘以一个$\lambda$,而此处是从每个非零计数中减掉一个固定的$\delta \in (0,1)$,一般取$\delta = 0.75$<br>在bigram中，公式为</p><script type="math/tex; mode=display">P_{AD}(w_i|w_{i-1}) = \frac{c(w_{i-1},w_i)-\delta}{c(w_{i-1})}+\lambda(w_{i-1})P(w))</script><p>其中$\lambda(w_{i-1})为插值权重系数$<br>于是完整的公式就是</p><script type="math/tex; mode=display">p_{abs}(w_i|w^i_{i-n+1}) = \frac{max\{c(w^i_{i-n+1})-\delta,0\}}{\sum_{w_i}c(w^i_{i-n+1})}+(1-\lambda_{w^{i-1}_{i-n+1}}p_{ab}(w_i|w^{i-1}{i-n+2}))</script><p>为了使得结果的总和为1</p><script type="math/tex; mode=display">1 - \lambda _ { w _ { i - n + 1 } } ^ { i - 1 } = \frac { \delta } { \sum _ { w _ { i } } c ( w _ { i - n + 1 } ^ { i } ) } N _ { 1 + } ( w _ { i - n + 1 } ^ { i - 1 }  \mathbf { \bullet } )</script><p>其中</p><script type="math/tex; mode=display">N _ { 1 + } \left( w _ { i - n + 1 } ^ { i - 1 }  \bullet \right) = \left| \left\{ w _ { i } : c \left( w _ { i - n + 1 } ^ { i - 1 } w _ { i } \right) > 0 \right\} \right|</script><h3 id="Kneser-Ney-smoothing"><a href="#Kneser-Ney-smoothing" class="headerlink" title="Kneser-Ney smoothing"></a>Kneser-Ney smoothing</h3><p>bigram下的公式:</p><script type="math/tex; mode=display">p _ { K N } \left( w _ { i } | w _ { i - 1 } \right) = \frac { \max \left( c \left( w _ { i - 1 } , w _ { i } \right) - \delta , 0 \right) } { \sum _ { w ^ { \prime } } c \left( w _ { i - 1 } , w ^ { \prime } \right) } + \lambda _ { w _ { i - 1 } } p _ { K N } \left( w _ { i } \right)</script><p>其中</p><script type="math/tex; mode=display">p _ { K N } \left( w _ { i } \right) = \frac { \left| \left\{ w ^ { \prime } : 0 < c \left( w ^ { \prime } , w _ { i } \right) \right\} \right| } { \left| \left\{ \left( w ^ { \prime } , w ^ { \prime \prime } \right) : 0 < c \left( w ^ { \prime } , w ^ { \prime \prime } \right) \right\} \right| }</script><p>为的是求解在一个不熟悉的上下文中看见单词$w_i$的可能性,这使用$w_i$在出现在所有单词的次数和除以所有bigram的和来衡量<br>减掉一个固定的$\delta \in (0,1)$,一般取$\delta = 0.75$<br>$\lambda_{w_{i-1}}$是用来平衡使得条件概率$p _ { K N } ( w _ { i } | w _ { i - 1 } )$的总和为1的系数<br>得出满足条件的$\lambda_{w_{i-1}}$结果为</p><script type="math/tex; mode=display">\lambda _ { w _ { i - 1 } } = \frac { \delta } { \sum _ { w ^ { \prime } } c \left( w _ { i - 1 } , w ^ { \prime } \right) } \left| \left\{ w ^ { \prime } : 0 < c \left( w _ { i - 1 } , w ^ { \prime } \right) \right\} \right|</script><p>可以推广到n-gram</p><script type="math/tex; mode=display">p _ { K N } \left( w _ { i } | w _ { i - n + 1 } ^ { i - 1 } \right) = \frac { \max \left( c \left( w _ { i - n + 1 } ^ { i - 1 } , w _ { i } \right) - \delta , 0 \right) } { \sum _ { w ^ { \prime } } c \left( w _ { i - n + 1 } ^ { i - 1 } , w ^ { \prime } \right) } + \delta \frac { \left| \left\{ w ^ { \prime } : 0 < c \left( w _ { i - n + 1 } ^ { i - 1 } , w ^ { \prime } \right) \right\} \right| } { \sum _ { w _ { i } } c \left( w _ { i - n + 1 } ^ { i } \right) } p _ { K N } \left( w _ { i } | w _ { i - n + 2 } ^ { i - 1 } \right)</script>]]></content>
      
      
      <categories>
          
          <category> Natural Language Processing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> smooth </tag>
            
            <tag> kneser-ney </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Trie树</title>
      <link href="/2018/11/04/trie/"/>
      <url>/2018/11/04/trie/</url>
      
        <content type="html"><![CDATA[<p>为了提高我的单词查找的速度，我拜读了<a href="https://github.com/Rshcaroline/FDU-Natural-Language-Processing/blob/master/Project%201.%20Spell%20Correction/spell_correction.py">@Rshcaroline</a>的代码，发现trie树是一个很好解决这个问题的方法</p><p>Trie树，又叫字典树、前缀树（Prefix Tree）、单词查找树 或 键树，是一种多叉树结构</p><p>Trie树的基本性质：</p><ol><li>根节点不包含字符，除根节点外的每一个子节点都包含一个字符。</li><li>从根节点到某一个节点，路径上经过的字符连接起来，为该节点对应的字符串。</li><li>每个节点的所有子节点包含的字符互不相同。<br>通常在实现的时候，会在节点结构中设置一个标志，用来标记该结点处是否构成一个单词（关键字）。</li></ol><p>为了了解它的实现，我从leetcode中找了题目<a href="https://leetcode.com/problems/implement-trie-prefix-tree/description/">Implement Trie (Prefix Tree)</a>做了一下</p><p>一下是我的代码</p><pre><code class="lang-python">class Trie:    def __init__(self):        &quot;&quot;&quot;        Initialize your data structure here.        &quot;&quot;&quot;        self.root = &#123;&#125;        self.END = &quot;$&quot;    def insert(self, word):        &quot;&quot;&quot;        Inserts a word into the trie.        :type word: str        :rtype: void        &quot;&quot;&quot;        t = self.root        for c in word:            if c not in t:                t[c] = &#123;&#125;            t = t[c]                        t[self.END] = &#123;&#125;            def search(self, word):        &quot;&quot;&quot;1        Returns if the word is in the trie.        :type word: str        :rtype: bool        &quot;&quot;&quot;        t = self.root        for c in word:            if c not in t:                return False            else:                t = t[c]            if self.END not in t:            return False        return True    def startsWith(self, prefix):        &quot;&quot;&quot;        Returns if there is any word in the trie that starts with the given prefix.        :type prefix: str        :rtype: bool        &quot;&quot;&quot;        t = self.root        for c in prefix:            if c not in t:                return False            else:                t = t[c]        return True</code></pre><p>对于一个单词的查找一定编辑距离的相关集合的代码如下(from <a href="https://github.com/Rshcaroline/FDU-Natural-Language-Processing/blob/master/Project%201.%20Spell%20Correction/spell_correction.py">@Rshcaroline</a>)，其中的deque是python的高性能双向队列，用于将trie,  word, path, edit_distance整个打包起来加入队列, 广度优先查找符合的单词</p><pre><code class="lang-python">def get_candidate(trie, word, edit_distance=1):    que = deque([(trie, word, &#39;&#39;, edit_distance)])    while que:        trie, word, path, edit_distance = que.popleft()        if word == &#39;&#39;:            if END in trie:                yield path            # 词尾增加字母            if edit_distance &gt; 0:                for k in trie:                    if k != END:                        que.appendleft((trie[k], &#39;&#39;, path+k, edit_distance-1))        else:            if word[0] in trie:                # 首字母匹配成功                que.appendleft((trie[word[0]], word[1:], path+word[0], edit_distance))            # 无论首字母是否匹配成功，都如下处理            if edit_distance &gt; 0:                edit_distance -= 1                for k in trie.keys() - &#123;word[0], END&#125;:                    # 用k替换余词首字母，进入trie[k]                    que.append((trie[k], word[1:], path+k, edit_distance))                    # 用k作为增加的首字母，进入trie[k]                    que.append((trie[k], word, path+k, edit_distance))                # 删除目标词首字母，保持所处结点位置trie                que.append((trie, word[1:], path, edit_distance))                # 交换目标词前两个字母，保持所处结点位置trie                if len(word) &gt; 1:                    que.append((trie, word[1]+word[0]+word[2:], path, edit_distance))</code></pre>]]></content>
      
      
      <categories>
          
          <category> Data Structure </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Trie </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring, Spring Boot, Restful, Docker</title>
      <link href="/2018/09/16/spring/"/>
      <url>/2018/09/16/spring/</url>
      
        <content type="html"><![CDATA[<h3 id="一、Restful"><a href="#一、Restful" class="headerlink" title="一、Restful"></a>一、Restful</h3><p>一个程序规范，一般会与http联系在一起。能够增加url的复用性，降低url的复杂性。<br>与GET、POST、PUT、DELETE等操作配合实现交互。</p><h3 id="二、Spring"><a href="#二、Spring" class="headerlink" title="二、Spring"></a>二、Spring</h3><p>一个JAVA框架, 通过高内聚的代码细节的隐藏，使得用户代码更加松耦合。</p><h4 id="IOC"><a href="#IOC" class="headerlink" title="IOC"></a>IOC</h4><p>Spring的重要逻辑之一，<strong>反转控制</strong>，将对象实例化的控制转移到外部代码中实现。常见的实现为DI(依赖注入)，外部代码将依赖对象产生后注入到内部代码里。<br>可以通过注解@autowired实现。</p><h4 id="Bean"><a href="#Bean" class="headerlink" title="Bean"></a>Bean</h4><p>Spring的重要概念之一，是<strong>能够暴露给Spring框架的特殊的类</strong>。可以通过注解@Controller、@Service、@repository产生，反转控制都是由Bean来完成的</p><h4 id="AOP"><a href="#AOP" class="headerlink" title="AOP"></a>AOP</h4><p>Spring的重要程序设计思想，<strong>面向切片编程</strong>，就是将一系列通用逻辑提取出来，进行复用。</p><h3 id="三、Spring-Boot"><a href="#三、Spring-Boot" class="headerlink" title="三、Spring Boot"></a>三、Spring Boot</h3><p>将Tomcat，Jetty等容器封装起来，使用application.yml文件控制，免去了大量使用中的初始化操作，使得Spring更易于使用。</p><h3 id="四、Docker"><a href="#四、Docker" class="headerlink" title="四、Docker"></a>四、Docker</h3><p>与虚拟机相比，虚拟机是将虚拟机系统与宿主操作系统分离，使用虚拟监视器来分隔，而Docker共用宿主的操作系统，因而不支持跨平台，但提供相对隔离的环境，同时有更高的效率。</p>]]></content>
      
      
      <categories>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
            <tag> Spring Boot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Vue项目bus与vuex的使用</title>
      <link href="/2018/09/03/vue-bus/"/>
      <url>/2018/09/03/vue-bus/</url>
      
        <content type="html"><![CDATA[<h3 id="为什么需要Bus"><a href="#为什么需要Bus" class="headerlink" title="为什么需要Bus"></a>为什么需要Bus</h3><p>一般来说，都是利用父组件给子组件使用query或者params传递参数来实现子组件的数据显示<br>不过，当出现子组件需要向父组件传递数据的时候，就需要用到bus，bus可以自己创建，也可以通过装包来实现</p><h3 id="直接创建Bus"><a href="#直接创建Bus" class="headerlink" title="直接创建Bus"></a>直接创建Bus</h3><p>在此处直接将Bus注入Vue对象中，成为全局的组件。<br>在子组件中通过this.$root.Bus.$on(key,method),this.$root.Bus.$emit(key,data)来调用<br>将$on放在mounted，created这些钩子函数中，相应的函数使用(e)=&gt;{function}比较便捷         </p><pre><code class="lang-js">import Vue from &#39;vue&#39;const Bus = new Vue()var app= new Vue(&#123;    el:&#39;#app&#39;,　　 data:&#123;　　　　Bus    &#125;　　&#125;)</code></pre><h3 id="使用vue-bus"><a href="#使用vue-bus" class="headerlink" title="使用vue-bus"></a>使用vue-bus</h3><p>使用yarn或者npm安装vue-bus之后，在main.js中引用它</p><pre><code class="lang-js">import VueBus from &#39;vue-bus&#39;;Vue.use(VueBus);</code></pre><p>于是调用直接可以写为 this.$bus.on(key, this.method)，this.$bus.emit(key, { text: …… }<br>其中第一个字符串参数代表key，每个key都能够实现自己的独立传输，this.method为事先定义好的method，用于对传入的数据进行处理</p><h3 id="为什么使用vuex"><a href="#为什么使用vuex" class="headerlink" title="为什么使用vuex"></a>为什么使用vuex</h3><p>当我们的应用遇到多个组件共享状态时，会需要：</p><ol><li>多个组件依赖于同一状态。</li><li>来自不同组件的行为需要变更同一状态。</li></ol><p>经过我的观察，vuex在其中的作用就是组件与状态的捆绑剥离开来，使得组件状态的改变依赖于某个行为，这使得代码变得易于调试。<br>Vuex采用集中式存储管理应用的所有组件的状态，这里的关键在于集中式存储管理。这意味着本来需要共享状态的更新是需要组件之间通讯的，而现在有了vuex，就组件就都和store通讯了。</p><h3 id="使用vuex"><a href="#使用vuex" class="headerlink" title="使用vuex"></a>使用vuex</h3><p>使用yarn或者npm安装vuex之后，在main.js中引用它</p><pre><code class="lang-js">import Vuex from &#39;vuex&#39;import store from &#39;./vuex/store&#39;Vue.use(Vuex)new Vue(&#123;  el: &#39;#app&#39;,  store&#125;)</code></pre><p>随后创建vuex目录,将store.js放在目录下,定义state和mutation</p><pre><code class="lang-js">import Vue from &#39;vue&#39;import Vuex from &#39;vuex&#39;Vue.use(Vuex)const store = new Vuex.Store(&#123;  state: &#123;    author: &#39;Wise Wrong&#39;  &#125;,  mutations:&#123;      newAuthor(state,msg)&#123;          state.author = msg      &#125;  &#125;&#125;)export default store</code></pre><p>在使用的时候，不直接修改this.$store.state.author，而是使用this.$store.commit()来提交，可以让我们更好的跟踪每一个状态的变化，在大型项目中更为适用</p>]]></content>
      
      
      <categories>
          
          <category> Vue </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vue </tag>
            
            <tag> router </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Vue项目路由传参</title>
      <link href="/2018/09/01/Vue-route-pamas/"/>
      <url>/2018/09/01/Vue-route-pamas/</url>
      
        <content type="html"><![CDATA[<h3 id="query传参"><a href="#query传参" class="headerlink" title="query传参"></a>query传参</h3><p>父组件通过path来配置路由，用query来传递参数</p><pre><code class="lang-js">    this.$router.push(&#123;          path: &#39;/describe&#39;,          query: &#123;            id: id          &#125;        &#125;)</code></pre><p>此时不需要在路由配置上做手脚，直接在子组件上使用params即可，注意此时是用route来表示，而不是用router<br>最终效果是query传递的参数会显示在url后面的?id=上</p><pre><code class="lang-js">this.$route.params.id</code></pre><h3 id="params传参"><a href="#params传参" class="headerlink" title="params传参"></a>params传参</h3><p>此时不过是用别名name来代替path，使用params代替query而已</p><pre><code class="lang-js">       this.$router.push(&#123;          name: &#39;Describe&#39;,          params: &#123;            id: id          &#125;        &#125;)</code></pre><p>同样的引用方式</p><pre><code class="lang-js">this.$route.params.id</code></pre><h3 id="router-push传参"><a href="#router-push传参" class="headerlink" title="$router.push传参"></a>$router.push传参</h3><p>父组件</p><pre><code class="lang-js">      getDescribe(id) &#123;//   直接调用$router.push 实现携带参数的跳转        this.$router.push(&#123;          path: `/describe/$&#123;id&#125;`,        &#125;)</code></pre><p>此时需要修改router中的index.js，需要在path中添加/:id来对应 $router.push 中path携带的参数</p><pre><code class="lang-js">&#123;     path: &#39;/describe/:id&#39;,     name: &#39;Describe&#39;,     component: Describe   &#125;</code></pre><p>同样的引用方式</p><pre><code class="lang-js">this.$route.params.id</code></pre>]]></content>
      
      
      <categories>
          
          <category> Vue </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vue </tag>
            
            <tag> router </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hackerrank Dicts 解题记录</title>
      <link href="/2018/08/31/dict_hr/"/>
      <url>/2018/08/31/dict_hr/</url>
      
        <content type="html"><![CDATA[<h3 id="Hash-Tables-Ransom-Note"><a href="#Hash-Tables-Ransom-Note" class="headerlink" title="Hash Tables: Ransom Note"></a><a href="https://www.hackerrank.com/challenges/ctci-ransom-note">Hash Tables: Ransom Note</a></h3><p>一道简易的题目，由于碰到了我经常用到的库 Counter，所以在此还是记录一下</p><pre><code class="lang-python">from collections import Counterdef checkMagazine(magazine, note):    magazineList =  Counter(magazine)    magazineDict = &#123;v:magazineList[v] for v in magazineList&#125;    noteList = Counter(note)    noteDict = &#123;v:noteList[v] for v in noteList&#125;    for v in noteDict:        if v not in magazineDict or magazineDict[v] &lt; noteDict[v]:            print(&quot;No&quot;)            return    print(&quot;Yes&quot;)    return</code></pre><p>对比一下其他人使用相同的库的代码，感觉别人写的实在是太骚了呀，深深感觉到自己的掌握还远远不够</p><pre><code class="lang-python">def checkMagazine(magazine, note):    if not (Counter(note) - Counter(magazine)):    # or Counter(note) - Counter(magazine) == &#123;&#125;        print(&quot;Yes&quot;)    else:        print(&quot;No&quot;)</code></pre><hr><h3 id="Sherlock-and-Anagrams"><a href="#Sherlock-and-Anagrams" class="headerlink" title="Sherlock and Anagrams"></a><a href="https://www.hackerrank.com/challenges/sherlock-and-anagrams">Sherlock and Anagrams</a></h3><p>一道中等难度的题目,最初采用将字符串都拆解成他们的不同字串的方法，结果超时了，想想也是，如果是100个字母长度的字符串，那么结果就是2<sup>100</sup>,不超时才怪。</p><pre><code class="lang-python">from collections import Counterdef checkAnag(a,b):    if Counter(a) == Counter(b):        return Truedef sherlockAndAnagrams(s):    count = 0    s1 = &quot;&quot;.join(reversed(s))    sub1 =[s1[i:i+x+1] for i in range(len(s1)) for x in range(len(s1)-i)]    if s1 in sub1:        sub1.remove(s1)    for i in range(len(sub1)):        for j in range(i+1,len(sub1)):            if checkAnag(sub1[i],sub1[j]):                count += 1    return count</code></pre><p>与其对其中的每一个字母进行计数，还不如将所有的字母都按顺序排列一遍，然后再比较最后的两个序列是否相同，此思路的实现代码如下</p><pre><code class="lang-python">def sherlockAndAnagrams(s):    count=0    dict=&#123;&#125;    n=len(s)    for i in range(n):        for j in range(n-i):            sub=&#39;&#39;.join(sorted(s[j:j+i+1]))            try:                dict[sub]+=1            except:                dict[sub]=1    for i in dict:        count+=dict[i]*(dict[i]-1)//2    return count</code></pre><hr><h3 id="Count-Triplets"><a href="#Count-Triplets" class="headerlink" title="Count Triplets"></a><a href="https://www.hackerrank.com/challenges/count-triplets-1">Count Triplets</a></h3><p>对三个数进行r倍组合，1为特殊情况，我直接用了组合计算，不过代码出现了超时，再研究研究哪里出了问题</p><pre><code class="lang-python">from collections import Counterfrom itertools import combinations# Complete the countTriplets function below.def combinationResult(num):    i = 0    for combination in combinations(range(num),3):        i += 1    return i def countTriplets(arr, r):    sum = 0    square = r**2    countNum = Counter(arr)    if r == 1:        for v in countNum:            if(countNum[v]&gt;2):                sum += combinationResult(countNum[v])        return sum    sortSet = list(sorted(set(arr)))    firstLimit = sortSet[len(sortSet)-1]/square    for x in sortSet:        if x &gt; firstLimit:            break        if x*r in sortSet and x*square in sortSet:            sum += countNum[x]*countNum[x*r]*countNum[x*square]    return sum</code></pre><p>关于组合数的计算，参见<a href="https://blog.csdn.net/weixin_41947081/article/details/80740756">python计算组合数的两种实现方法</a><br>经过对两种方法(直接进行组合与笛卡尔乘积)的比对，得出直接利用combinations来计算更加迅速一些,以下为比较代码：</p><pre><code class="lang-python">import mathimport itertoolsimport timefrom itertools import combinationsunique = [1, 2, 3, 4, 5, 56, 78, 23]time1 = time.time()for j in range(1000000):    i = 0    for combination in combinations(unique, 2):        i += 1time2 = time.time()for j in range(1000000):    d = 0    uniques = [unique, unique]    for combination in itertools.product(*uniques):        d += 1time3 = time.time()print(&quot;time 2-1 = &quot;+str(time2-time1), &quot;time 3-1 = &quot;+str(time3-time2))#time 2-1 = 3.7130393981933594 time 3-1 = 7.952743053436279</code></pre><p>为了将这道题解决，我看了一下出题者的解释，在出题者的hint中提到本题是能够达到O(n)的复杂度的，反观一下自己，虽然自己并没有写什么循环，不过的话在循环里的if语句中用到了两个in，基本算是O(n<sup>3</sup>)的复杂度了。<br>按照作者的意思，作者进行个对arr的遍历，建立两个字典，假设三元组为(A，B，C)，两个字典分别是指对于B来说A已经存在了，以及对于C来说（A，B）的组合已经准备好了。<br>每个字典里面放的并不是实值，而是对于未来三元组的一个可能性的预测，在遍历每个A的同时让B与C的线性空间不断减小，是一个非常有意思的解决思路。以下是它的python代码。</p><pre><code class="lang-python">def countTriplets(arr, r):    r2 = Counter()    r3 = Counter()    count = 0    for v in arr:        if v in r3:            count += r3[v]        if v in r2:            r3[v*r] += r2[v]        r2[v*r] += 1    return count</code></pre>]]></content>
      
      
      <categories>
          
          <category> hackerrank </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hackerrank </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hackerrank Arrays 解题记录</title>
      <link href="/2018/08/30/list_hr/"/>
      <url>/2018/08/30/list_hr/</url>
      
        <content type="html"><![CDATA[<h3 id="New-Year-Chaos"><a href="#New-Year-Chaos" class="headerlink" title="New Year Chaos"></a><a href="https://www.hackerrank.com/challenges/new-year-chaos/">New Year Chaos</a></h3><p>看到这道题目最初使用了冒泡排序的方法，发现在第6-9组测试中出现了超时</p><pre><code class="lang-python">def minimumBribes(q):    time = 0    for i,v in enumerate(q):        if (v-1)-i &gt; 2:                print(&quot;Too chaotic&quot;)            return    lastIndex =  len(q)-1    for j in range(0,lastIndex):        for i in range(0,lastIndex):            if q[i]&gt;q[i+1]:                q[i+1],q[i] = q[i],q[i+1]                time = time+1    if q ==list(range(1,lastIndex+2)):        print(str(time))        return</code></pre><p>回头观察发现数据的复杂度达到了10<sup>5</sup>，时间仅仅允许为10秒，而cpu最快能够达到每秒操作1亿次，因此至少需要100秒才能执行完毕，明显超时</p><p>之后尝试使用归并排序来计算，当右边先添加到序列中的时候会统计左边还剩下的元素，这一样会出现有时左边的元素出现得过多然后直接移动很多位的情况，此时算法因为没有考虑两位的限制而出错。结果出现小的样本都通过了，大的样本却没有通过的情况</p><pre><code class="lang-python">def merge(a,b):    c = []    h = j = 0    global time    while j &lt; len(a) and h &lt; len(b):        if a[j] &lt; b[h]:            c.append(a[j])            j += 1               time = time + (len(a)-j)            c.append(b[h])            h += 1    if j == len(a):        for i in b[h:]:            c.append(i)    else:        for i in a[j:]:            c.append(i)    return cdef merge_sort(lists):    if len(lists) &lt;= 1:        return lists    middle = int(len(lists)/2)    left = merge_sort(lists[:middle])    right = merge_sort(lists[middle:])    return merge(left, right)def minimumBribes(q):    global time    for i,v in enumerate(q):        if (v-1)-i &gt; 2:                print(&quot;Too chaotic&quot;)            return    merge_sort(q)    print(str(time))    return</code></pre><p>尝试解题失败，以下是对正确答案的观察，令我非常惊奇的是在数据量非常大的情况下python的字典依然正常运行而且没有出现Runtime Error<br>以下解题的思路是当存在可以交换的项的时候，继续保持大循环的执行，而不是使用外层n的大循环来绑定。导致了循环复杂度不再是n<sup>2</sup>,这属于什么排序我说不清楚，应该来说，这个算法利用了元素本身并没有过大位移的特征降下了复杂度</p><pre><code class="lang-python">b = &#123;&#125;r = 0cont = Truewhile cont:    cont = False    for i in range(len(q)-1):        if q[i] &gt; q[i+1]:            if not q[i] in b:                b[q[i]] = 0            b[q[i]] += 1            if b[q[i]] &gt; 2:                cont = False                r = &quot;Too chaotic&quot;                break            print(q)            q[i], q[i+1] = q[i+1], q[i]            r += 1            cont = True            print(b)print(r)#对其结果进行打印观察如下[1, 2, 5, 3, 7, 8, 6, 4]&#123;5: 1&#125;[1, 2, 3, 5, 7, 8, 6, 4]&#123;5: 1, 8: 1&#125;[1, 2, 3, 5, 7, 6, 8, 4]&#123;5: 1, 8: 2&#125;[1, 2, 3, 5, 7, 6, 4, 8]&#123;5: 1, 8: 2, 7: 1&#125;[1, 2, 3, 5, 6, 7, 4, 8]&#123;5: 1, 8: 2, 7: 2&#125;[1, 2, 3, 5, 6, 4, 7, 8]&#123;5: 1, 8: 2, 7: 2, 6: 1&#125;[1, 2, 3, 5, 4, 6, 7, 8]&#123;5: 2, 8: 2, 7: 2, 6: 1&#125;7</code></pre><p>python标准答案给出的逻辑就比较难以看懂,而C++的代码就是利用BIT(二叉索引树)的方法来解决，具体二叉索引树是什么来日再研究<br><a href="https://www.cnblogs.com/gangding/articles/4765885.html">区间信息的维护与查询（一）——二叉索引树（Fenwick树、树状数组）</a></p><pre><code class="lang-C">#include &lt;bits/stdc++.h&gt;using namespace std;const int maxN=2e5+5;int n,a[maxN],ans,T,k;int bit[maxN];int invalid;void del() &#123;    for (k=0;k&lt;maxN;k++) &#123;        bit[k]=0;            &#125;    ans = 0;    invalid = 0;&#125;void upd(int x) &#123;    for (k = x; k &lt; maxN; k += (k &amp; (-k))) &#123;        bit[k]++;    &#125;&#125;int get_sum(int x) &#123;    int p = 0;    for (k = x; k &gt; 0; k -= (k &amp; (-k)))        p += bit[k];        return p;&#125;int main() &#123;    scanf(&quot;%d&quot;, &amp;T);    while (T--) &#123;        del();        scanf(&quot;%d&quot;, &amp;n);        for (int i = 0; i &lt; n; i++) &#123;            scanf(&quot;%d&quot;, &amp;a[i]);        &#125;        for (int i = n - 1; i &gt;= 0; i--) &#123;            if (get_sum(a[i]) &gt; 2)                invalid++;            ans += get_sum(a[i]);            upd(a[i]);        &#125;        if (invalid &gt; 0) &#123;            printf(&quot;Too chaotic\n&quot;);        &#125; else &#123;            printf(&quot;%d\n&quot;, ans);        &#125;   &#125;   return 0;&#125;</code></pre><hr><h3 id="Minimum-Swaps-2"><a href="#Minimum-Swaps-2" class="headerlink" title="Minimum Swaps 2"></a><a href="https://www.hackerrank.com/challenges/minimum-swaps-2">Minimum Swaps 2</a></h3><p>本题需要找到最少的交换方式，可以知道，在正确的排序下，如果一个元素不在正确的排序的索引位置，那么它正确的索引位置上元素肯定是不正确的。<br>那么只需要去和这个位置的元素交换，就能够逐步将每个位置排好了<br>需要注意的点是，在每次交换元素时，相应的索引需要立即交换</p><pre><code class="lang-python">def minimumSwaps(arr):    rightArr = sorted(arr)    Idx = &#123;v: i for i,v in enumerate(arr)&#125;    count = 0    for i,v in enumerate(arr):        rightNum = rightArr[i]        if v != rightNum:            arr[i],arr[Idx[rightNum]] = arr[Idx[rightNum]],arr[i]            Idx[v],Idx[rightNum] = Idx[rightNum],Idx[v]            count = count + 1    return count</code></pre>]]></content>
      
      
      <categories>
          
          <category> hackerrank </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hackerrank </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Vue、Loopback、mysql</title>
      <link href="/2018/08/24/connectlb/"/>
      <url>/2018/08/24/connectlb/</url>
      
        <content type="html"><![CDATA[<h3 id="Vue中调用Loopback进行增删改查"><a href="#Vue中调用Loopback进行增删改查" class="headerlink" title="Vue中调用Loopback进行增删改查"></a>Vue中调用Loopback进行增删改查</h3><p>使用npm或者yarn安装axios，然后利用axios.patch,axios.delete,axios.get调用Loopback后端api进行数据的显示和增删改查</p><h3 id="关于跨域访问的配置问题"><a href="#关于跨域访问的配置问题" class="headerlink" title="关于跨域访问的配置问题"></a>关于跨域访问的配置问题</h3><p>配置vue项目下的config/index.js<br>如要请求的地址是localhost:3000/api/1，可以对proxyTable进行如下配置：</p><pre><code class="lang-js">proxyTable: &#123;      &#39;/api&#39;: &#123;        target: &#39;http://localhost:3000&#39;,        changeOrigin: true,        pathRewrite: &#123;          &#39;^/api&#39;: &#39;/api&#39;        &#125;      &#125;    &#125;</code></pre><p>如此一来就可以用/api/1来代替localhost:3000/api/1</p><p>参考<a href="https://www.jianshu.com/p/75a9f9b5a1bb">使用vue.js的proxyTable解决跨域问题</a></p><h3 id="Vue连接mysql"><a href="#Vue连接mysql" class="headerlink" title="Vue连接mysql"></a>Vue连接mysql</h3><p>首先使用lb datasource来创建新的数据源，随后在server/datasource中修改数据源，name一般数据源同名，user为root，host为localhost，port为mysql的端口号</p><h3 id="将数据迁移到数据库中"><a href="#将数据迁移到数据库中" class="headerlink" title="将数据迁移到数据库中"></a>将数据迁移到数据库中</h3><p>查询server/model-config来查看有多少个表<br>随后在boot中新建migration.js进行数据迁移</p><pre><code class="lang-js">&#39;use strict&#39;;module.exports = function enableAuthentication(server) &#123;  let dataSources = server.dataSources  let db = dataSources.db  db.autoupdate([&#39;Note&#39;], function (err, result) &#123;       //此处将Note迁移到数据库中    console.log(&#39;migration success&#39;)        //迁移成功之后会在console中打印成功提示  &#125;);&#125;;</code></pre><h3 id="api复用"><a href="#api复用" class="headerlink" title="api复用"></a>api复用</h3><p>新建service文件夹，建立noteService.js等代码，建立Loopback接口的复用</p>]]></content>
      
      
      <categories>
          
          <category> Vue </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vue </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Vue组件的使用</title>
      <link href="/2018/08/23/Vue_component/"/>
      <url>/2018/08/23/Vue_component/</url>
      
        <content type="html"><![CDATA[<h3 id="组件的复用"><a href="#组件的复用" class="headerlink" title="组件的复用"></a>组件的复用</h3><p>组件可以被复用，且复用组件的内容由每一个实例自己维护。但是复用组件的data选项必须是一个函数。</p><h3 id="子组件向复用组件触发事件"><a href="#子组件向复用组件触发事件" class="headerlink" title="子组件向复用组件触发事件"></a>子组件向复用组件触发事件</h3><p>我们在子组件中引用复用组件时，点击复用组件的按钮，我们希望能够将时间传递到复用组件中去，这时候我们需要用$emit方法传入事件，并且在复用组件的模板中使用v-on:来启动相应的方法</p><p>对于$emit方法的第二个参数,可以在复用组件里使用$event获取，当复用组件定义了相应的方法时，可以作为函数的参数使用</p>]]></content>
      
      
      <categories>
          
          <category> Vue </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vue </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Vue项目v-for、v-model的使用</title>
      <link href="/2018/08/23/Vueform/"/>
      <url>/2018/08/23/Vueform/</url>
      
        <content type="html"><![CDATA[<h2 id="V-for"><a href="#V-for" class="headerlink" title="V-for"></a>V-for</h2><p>v-for既可以在data内的一个对象列表中循环，也可以在一个对象中循环</p><ol><li>当作为一个对象列表循环的时候，每个对象是一个字典，字典中的内容可以作为:key的循环索引</li><li>当对一个对象进行循环的时候，会对对想的属性的内容依次循环展示（并不算有什么价值）</li></ol><h3 id="v-for-响应的内容更新"><a href="#v-for-响应的内容更新" class="headerlink" title="v-for 响应的内容更新"></a>v-for 响应的内容更新</h3><p> 可以使用vm.$set(vm.items, indexOfItem, newValue)对items第i个内容进行修改，并且v-for会实时响应更新，如果是items[i]则不行</p><h3 id="利用过滤创立新数组"><a href="#利用过滤创立新数组" class="headerlink" title="利用过滤创立新数组"></a>利用过滤创立新数组</h3><p> 可以建立以下method</p><pre><code class="lang-js">methods: &#123;  even: function (numbers) &#123;    return numbers.filter(function (number) &#123;      return number % 2 === 0    &#125;)  &#125;&#125;</code></pre><p>当进行引用的时候就使用even(numbers)来代表新数组</p><h3 id="v-for-与-v-if-的合并使用"><a href="#v-for-与-v-if-的合并使用" class="headerlink" title="v-for 与 v-if 的合并使用"></a>v-for 与 v-if 的合并使用</h3><p>v-for 的优先级比 v-if 更高，这意味着 v-if 将分别重复运行于每个 v-for 循环中。也可以达到如上过滤效果。</p><h2 id="V-model"><a href="#V-model" class="headerlink" title="V-model"></a>V-model</h2><p>v-model对数据进行动态绑定。</p><ol><li>特别的，对于特定的小组件比如列表中的某个选项，可以通过value来绑定的值，当它被选定时就会加入数组列表之中</li><li>更特别的，对于checkbox来说，value就包含true和false</li></ol>]]></content>
      
      
      <categories>
          
          <category> Vue </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vue </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Vue项目router注意事项</title>
      <link href="/2018/08/23/Vue-router/"/>
      <url>/2018/08/23/Vue-router/</url>
      
        <content type="html"><![CDATA[<h3 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h3><h4 id="main-js"><a href="#main-js" class="headerlink" title="main.js"></a>main.js</h4><p>在项目中唯一new了一次Vue，实现了App.vue的挂载，以及router与Vue的关联</p><h4 id="App-vue"><a href="#App-vue" class="headerlink" title="App.vue"></a>App.vue</h4><p>项目中的最外层的一个Vue，其中的router-view代表了可以变化和跳转的部分，如果内容写在router-view之外的话就无法跳转<br>并暴露了App接口，用于其他文件的引用</p><h4 id="route-index-js"><a href="#route-index-js" class="headerlink" title="route/index.js"></a>route/index.js</h4><p>用于在Vue中设置router，统一暴露所有的路由接口为router</p><h3 id="components-HelloWorld-vue"><a href="#components-HelloWorld-vue" class="headerlink" title="components/HelloWorld.vue"></a>components/HelloWorld.vue</h3><p>可以使用router-link to:=””来进行路由，其中的内容可以是button或者其他组件，对于components里的组件的引用，可以使用@/components/xxx来引用</p>]]></content>
      
      
      <categories>
          
          <category> Vue </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vue </tag>
            
            <tag> router </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CS APP malloclab</title>
      <link href="/2018/08/14/malloclab/"/>
      <url>/2018/08/14/malloclab/</url>
      
        <content type="html"><![CDATA[<h3 id="整体逻辑"><a href="#整体逻辑" class="headerlink" title="整体逻辑"></a>整体逻辑</h3><p>本项目实现堆的初始化，内存分配，内存释放以及内存的再分配。<br>在内存分配的过程中，我使用了以下的策略匹配，并分别得出了下列分数。最终采用了显式空闲链表+首次适配+立即合并的策略匹配。</p><ol><li>隐式空闲链表+首次适配+立即合并，util（51）+thru（1）=51，吞吐率很小，因为每次malloc的时候需要从头遍历所有的快，立即合并会发生抖动</li><li>隐式空闲链表+最佳适配+延迟合并，util（46）+thru（1）=46，</li><li>隐式空闲链表+最佳适配+立即合并，util（46）+thru（1）=46，后面两组数据很差</li><li>隐式空闲链表+首次适配+延迟合并，util（47）+thru（1）=47，</li><li>显式空闲链表+首次适配+立即合并，util(46)+thru(40)=86.<br>对于堆的一致性检查，对于最小块的检查，并且打印  </li></ol><pre><code class="lang-c">#include &lt;stdbool.h&gt;#include &lt;stdint.h&gt;#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &quot;memlib.h&quot;#include &quot;mm.h&quot;//* Basic constants and macros: */#define WSIZE      4              /* Word and header/footer size (bytes) */#define DSIZE      8              /* Doubleword size (bytes) */#define CHUNKSIZE  (1 &lt;&lt; 12)      /* Extend heap by this amount (bytes) *//*Max value of 2 values*/#define MAX(x, y) ((x) &gt; (y) ? (x) : (y))/* Pack a size and allocated bit into a word */#define PACK(size, alloc)  ((size) | (alloc))/* Read and write a word at address p. */#define GET(p)       (*(uintptr_t *)(p))#define PUT(p, val)  (*(uintptr_t *)(p) = (val))/* Read the size and allocated fields from address p */#define GET_SIZE(p)   (GET(p) &amp; ~(DSIZE - 1))#define GET_ALLOC(p)  (GET(p) &amp; 0x1)/* Given block ptr bp, compute address of its header and footer */#define HDRP(bp)  ((void *)(bp) - WSIZE)#define FTRP(bp)  ((void *)(bp) + GET_SIZE(HDRP(bp)) - DSIZE)/* Given block ptr bp, compute address of next and previous blocks */#define NEXT_BLK(bp)  ((void *)(bp) + GET_SIZE(HDRP(bp)))#define PREV_BLK(bp)  ((void *)(bp) - GET_SIZE((void *)(bp) - DSIZE))/* Given ptr in free list, get next and previous ptr in the list *//* bp is address of the free block. Since minimum Block size is 16 bytes,    we utilize to store the address of previous block pointer and next block pointer.*/#define GET_NEXT_PTR(bp)  (*(char **)(bp + WSIZE))#define GET_PREV_PTR(bp)  (*(char **)(bp))/* Puts pointers in the next and previous elements of free list */#define SET_NEXT_PTR(bp, qp) (GET_NEXT_PTR(bp) = qp)#define SET_PREV_PTR(bp, qp) (GET_PREV_PTR(bp) = qp)/* Global declarations */static char *heap_listp = 0; static char *free_list_start = 0;/* Function prototypes for internal helper routines */static void *coalesce(void *bp);static void *extend_heap(size_t words);static void *find_fit(size_t asize);static void place(void *bp, size_t asize);/* Function prototypes for maintaining free list*/static void insert_in_free_list(void *bp); static void remove_from_free_list(void *bp); /* Function prototypes for heap consistency checker routines: */static void checkblock(void *bp);static void checkheap(bool verbose);static void printblock(void *bp); // void *calloc (size_t nmemb, size_t size);</code></pre><h3 id="建立序言快"><a href="#建立序言快" class="headerlink" title="建立序言快"></a>建立序言快</h3><p>对内存进行创建，得到最初的空堆，建立序言块</p><pre><code class="lang-c">/**  * mm_init -  */int mm_init(void) &#123;  if ((heap_listp = mem_sbrk(8*WSIZE)) == NULL)     return -1;  PUT(heap_listp, 0);                            /* 对齐填充 */  PUT(heap_listp + (1 * WSIZE), PACK(DSIZE, 1)); /* 序章标题 */   PUT(heap_listp + (2 * WSIZE), PACK(DSIZE, 1)); /* 页脚*/   PUT(heap_listp + (3 * WSIZE), PACK(0, 1));     /* 结尾标题 */  free_list_start = heap_listp + 2*WSIZE;  //链表中现在只有一个序言块 //初始化堆空间4KB  if (extend_heap(4) == NULL)&#123;     return -1;  &#125;  return 0;&#125;</code></pre><h3 id="拓展堆"><a href="#拓展堆" class="headerlink" title="拓展堆"></a>拓展堆</h3><p>用一个新的空块扩展堆，分配时保持对齐，并且设置块的头，同时与前一个块（如果有）合并</p><pre><code class="lang-c">static void *extend_heap(size_t words) &#123;  char *bp;  size_t size;  size = (words % 2) ? (words+1) * WSIZE : words * WSIZE;  //最小块16字节，4字  if (size &lt; 16)&#123;    size = 16;  &#125;  /* call for more memory space */  if ((int)(bp = mem_sbrk(size)) == -1)&#123;     return NULL;  &#125;  PUT(HDRP(bp), PACK(size, 0));         /* free block header */  PUT(FTRP(bp), PACK(size, 0));         /* free block footer */  PUT(HDRP(NEXT_BLK(bp)), PACK(0, 1)); /* 新的结尾标题 */  /* 合并下一个和前一块bp */  return coalesce(bp);&#125;/*  *在bp（地址）的开始处放置指定size的块 */static void place(void *bp, size_t asize)&#123;  size_t csize = GET_SIZE(HDRP(bp));  if ((csize - asize) &gt;= 4 * WSIZE) &#123;    //如果剩余的大小（分配减去需求）大于最小块的大小，进行分割，剩余的快就会变成一个空闲块    PUT(HDRP(bp), PACK(asize, 1));    PUT(FTRP(bp), PACK(asize, 1));    remove_from_free_list(bp);    bp = NEXT_BLK(bp);    //设置下一个快的属性，大小就是剩余块的大小    PUT(HDRP(bp), PACK(csize-asize, 0));    PUT(FTRP(bp), PACK(csize-asize, 0));    coalesce(bp);  &#125;  else &#123;    PUT(HDRP(bp), PACK(csize, 1));    PUT(FTRP(bp), PACK(csize, 1));    remove_from_free_list(bp);  &#125;&#125;</code></pre><h3 id="内存分配"><a href="#内存分配" class="headerlink" title="内存分配"></a>内存分配</h3><p>如果有可以分配的块就分配，否则就进行堆拓展，对比我们的初始化堆和需要分配的大小，向我们的堆空间申请额外的空间，进行堆拓展</p><pre><code class="lang-c">void *mm_malloc(size_t size) &#123;  size_t asize;      /* 调整块大小 */  size_t extendsize; /* 如果不合适，则扩展堆的数量*/  void *bp;  /* Ignore spurious requests. */  if (size == 0)    return (NULL);  /* 调整块大小以包括开销和对齐请求 */  if (size &lt;= DSIZE)    asize = 2 * DSIZE;  else    asize = DSIZE * ((size + DSIZE + (DSIZE - 1)) / DSIZE);  if ((bp = find_fit(asize)) != NULL) &#123;    //如果找到可以分配的块就分配    place(bp, asize);    return (bp);  &#125;  //否则就进行堆拓展  extendsize = MAX(asize, CHUNKSIZE);  if ((bp = extend_heap(extendsize / WSIZE)) == NULL)      return (NULL);  place(bp, asize);  return (bp);&#125;</code></pre><h3 id="合并块"><a href="#合并块" class="headerlink" title="合并块"></a>合并块</h3><p>“bp” 是新释放的块的地址，合并边界标记，删除并插入空闲块指针到显示空闲列表，返回合并地址<br>先去检查前后是否有空闲块，并是否满足前后空闲块和当前已分配的空闲块size相加大于newsize，<br>如果是则合并，不需要再重新请求空闲块。<br>如果不行，则需要重新mm_malloc一块新的空间</p><pre><code class="lang-c">static void *coalesce(void *bp)&#123;  //读取大小和分配的字段，如果之前的被设置或者为0  size_t NEXT_ALLOC = GET_ALLOC(  HDRP(NEXT_BLK(bp))  );  size_t PREV_ALLOC = GET_ALLOC(  FTRP(PREV_BLK(bp))  ) || PREV_BLK(bp) == bp;  size_t size = GET_SIZE(HDRP(bp));  /* 下一块空闲，就将size加上下一块区域的大小，将下一个区域从空闲列表中移除*/     if (PREV_ALLOC &amp;&amp; !NEXT_ALLOC) &#123;                      size += GET_SIZE( HDRP(NEXT_BLK(bp))  );    remove_from_free_list(NEXT_BLK(bp));    PUT(HDRP(bp), PACK(size, 0));    //此时加上size之后的foot已经变成了新的foot    PUT(FTRP(bp), PACK(size, 0));  &#125;  /* 上一块空闲，就将size加上上一块区域的大小，将上一个区域从空闲列表中移除*/    else if (!PREV_ALLOC &amp;&amp; NEXT_ALLOC) &#123;                   size += GET_SIZE( HDRP(PREV_BLK(bp))  );    //添上前一个块的时候，bp的头要放到前一个块的位置    bp = PREV_BLK(bp);    remove_from_free_list(bp);    PUT(HDRP(bp), PACK(size, 0));    PUT(FTRP(bp), PACK(size, 0));  &#125;  /* 都空闲，就将size加上上一块区域和下一块区域的大小，将上下两区域从空闲列表中移除 */   else if (!PREV_ALLOC &amp;&amp; !NEXT_ALLOC) &#123;                    size += GET_SIZE( HDRP(PREV_BLK(bp))  ) + GET_SIZE( HDRP(NEXT_BLK(bp))  );    remove_from_free_list(PREV_BLK(bp));    remove_from_free_list(NEXT_BLK(bp));    bp = PREV_BLK(bp);    PUT(HDRP(bp), PACK(size, 0));    PUT(FTRP(bp), PACK(size, 0));  &#125;/* 最后将bp插入空闲列表并返回bp */  insert_in_free_list(bp);  return bp;&#125;</code></pre><h3 id="寻找合适堆"><a href="#寻找合适堆" class="headerlink" title="寻找合适堆"></a>寻找合适堆</h3><p>下面是对合适的堆的寻找，在列表中寻找合适大小的块，一直找到合适的就返回。如果相同的malloc请求连续进行了很多次大于40次，花费时间很长，直接把堆扩展到所需要的数量</p><pre><code class="lang-c">/* *下面是对合适的堆的寻找 *在列表中寻找合适大小的块，一直找到合适的就返回 *如果相同的malloc请求连续进行了很多次大于40次，花费时间很长，直接把堆扩展到所需要的数量 * */static void *find_fit(size_t asize)&#123;  void *bp;  static int last_malloced_size = 0;  static int repeat_counter = 0;  if( last_malloced_size == (int)asize)&#123;      if(repeat_counter&gt;40)&#123;          int extendsize = MAX(asize, 4 * WSIZE);        bp = extend_heap(extendsize/4);        return bp;      &#125;      else        repeat_counter++;  &#125;  else    repeat_counter = 0;  //在列表中寻找合适大小的块，一直找到合适的就返回  for (bp = free_list_start; GET_ALLOC(HDRP(bp)) == 0; bp = GET_NEXT_PTR(bp) )&#123;    if (asize &lt;= (size_t)GET_SIZE(HDRP(bp)) ) &#123;      last_malloced_size = asize;      return bp;    &#125;  &#125;  return NULL;&#125;</code></pre><h3 id="内存回收"><a href="#内存回收" class="headerlink" title="内存回收"></a>内存回收</h3><p>回收我们的内存，有用有还</p><pre><code class="lang-c">void mm_free(void *bp)&#123;  size_t size;  /* Ignore spurious requests. */  if (bp == NULL)    return;  /* Free and coalesce the block. */  size = GET_SIZE(HDRP(bp));  PUT(HDRP(bp), PACK(size, 0));  PUT(FTRP(bp), PACK(size, 0));  coalesce(bp);&#125;</code></pre><h3 id="内存再分配"><a href="#内存再分配" class="headerlink" title="内存再分配"></a>内存再分配</h3><p>以下是内存的再分配，参数bp是分配的块或者null;</p><ol><li>如果大小为0,则释放块bp，并且返回null</li><li>请求的size小于旧的块，那么返回bp</li><li>当大于，如果下一块恰好是空的，那么和当前的合并;此时不需要malloc，只需调整他们的大小</li><li><p>如果没有，那么malloc一个新的块，bp被复制到这个新的块，返回这个地址</p><pre><code class="lang-c">void *mm_realloc(void *bp, size_t size)&#123;if((int)size &lt; 0)  return NULL; else if((int)size == 0)&#123;  mm_free(bp);  return NULL; &#125; else if(size &gt; 0)&#123;    size_t oldsize = GET_SIZE(HDRP(bp));    size_t newsize = size + 2 * WSIZE; // 页眉和页脚的2个字   /*如果小于 */   if(newsize &lt;= oldsize)&#123;        return bp;    &#125;   /*如果大于*/    else &#123;        size_t next_alloc = GET_ALLOC(HDRP(NEXT_BLK(bp)));        size_t csize;       /* 如果下一块空闲，并且大小&gt;=新的*/        if(!next_alloc &amp;&amp; ((csize = oldsize + GET_SIZE(  HDRP(NEXT_BLK(bp))  ))) &gt;= newsize)&#123;          remove_from_free_list(NEXT_BLK(bp));          PUT(HDRP(bp), PACK(csize, 1));          PUT(FTRP(bp), PACK(csize, 1));          return bp;        &#125;       else &#123;           void *new_ptr = mm_malloc(newsize);           place(new_ptr, newsize);         memcpy(new_ptr, bp, newsize);          mm_free(bp);          return new_ptr;        &#125;    &#125;&#125;else  return NULL;&#125;</code></pre><h3 id="calloc-函数"><a href="#calloc-函数" class="headerlink" title="calloc 函数"></a>calloc 函数</h3><p>以下是calloc的实现，calloc相当于size个nmenb的内存分配<br>```c<br>void <em>mm_calloc (size_t nmemb, size_t size)<br>{<br> size_t bytes = nmemb </em> size;<br> void *newptr;</p><p> newptr = mm_malloc(bytes);<br> memset(newptr, 0, bytes);</p><p> return newptr;<br>}</p></li></ol><pre><code>### 其他```c/*将空闲指针插入free_list*/static void insert_in_free_list(void *bp)&#123;  SET_NEXT_PTR(bp, free_list_start);   SET_PREV_PTR(free_list_start, bp);   SET_PREV_PTR(bp, NULL);   free_list_start = bp; &#125;/*删除空闲指针*/static void remove_from_free_list(void *bp)&#123;  if (GET_PREV_PTR(bp))    SET_NEXT_PTR(GET_PREV_PTR(bp), GET_NEXT_PTR(bp));  else    free_list_start = GET_NEXT_PTR(bp);  SET_PREV_PTR(GET_NEXT_PTR(bp), GET_PREV_PTR(bp));&#125;/* *对块bp进行最小块的检查 */static void checkblock(void *bp) &#123;  if ((uintptr_t)bp % DSIZE)    printf(&quot;Error: %p不是双字对齐的\n&quot;, bp);  if (GET(HDRP(bp)) != GET(FTRP(bp)))    printf(&quot;Error: 标题不匹配页脚\n&quot;);&#125;/*  *对最小堆的一致性检查 */void checkheap(bool verbose) &#123;  void *bp;  if (verbose)    printf(&quot;Heap (%p):\n&quot;, heap_listp);  if (GET_SIZE(HDRP(heap_listp)) != DSIZE ||      !GET_ALLOC(HDRP(heap_listp)))    printf(&quot;错的序幕标题\n&quot;);  checkblock(heap_listp);  for (bp = heap_listp; GET_SIZE(HDRP(bp)) &gt; 0; bp = (void *)NEXT_BLK(bp)) &#123;    if (verbose)      printblock(bp);    checkblock(bp);  &#125;  if (verbose)    printblock(bp);  if (GET_SIZE(HDRP(bp)) != 0 || !GET_ALLOC(HDRP(bp)))    printf(&quot;错的结尾标题\n&quot;);&#125;/* *打印块bp */static void printblock(void *bp) &#123;  bool halloc, falloc;  size_t hsize, fsize;  checkheap(false);  hsize = GET_SIZE(HDRP(bp));  halloc = GET_ALLOC(HDRP(bp));    fsize = GET_SIZE(FTRP(bp));  falloc = GET_ALLOC(FTRP(bp));    if (hsize == 0) &#123;    printf(&quot;%p: end of heap\n&quot;, bp);    return;  &#125;  printf(&quot;%p: header: [%zu:%c] footer: [%zu:%c]\n&quot;, bp,       hsize, (halloc ? &#39;a&#39; : &#39;f&#39;),       fsize, (falloc ? &#39;a&#39; : &#39;f&#39;));&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> ICS lab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ICS </tag>
            
            <tag> CS APP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CS APP proxylab</title>
      <link href="/2018/08/14/proxylab/"/>
      <url>/2018/08/14/proxylab/</url>
      
        <content type="html"><![CDATA[<p>本项目要求实现一个代理服务器，从服务器拿到消息，发回给客户端，主要涉及一个读写上的竞争问题，本人使用信号量来解决。</p><pre><code class="lang-c">#include &lt;stdio.h&gt;#include &lt;ctype.h&gt;#include &quot;csapp.h&quot;/* Recommended max cache and object sizes */#define MAX_CACHE_SIZE 1049000#define MAX_OBJECT_SIZE 102400/* You won&#39;t lose style points for including this long line in your code */static const char *user_agent_hdr = &quot;User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:10.0.3) Gecko/20120305 Firefox/10.0.3\r\n&quot;;static const char *connect_hdr = &quot;Connection: close\r\n&quot;;static const char *proxy_hdr = &quot;Proxy-Connection: close\r\n&quot;;static const char *connection_key = &quot;Connection&quot;;static const char *user_agent_key= &quot;User-Agent&quot;;static const char *proxy_connection_key = &quot;Proxy-Connection&quot;;static const char *host_key = &quot;Host&quot;;#define EOF_TYPE 1#define HOST_TYPE 2#define OTHER_TYPE 3#define CACHE_NUM 10int getType(char *buf);void doit(int connfd);void parseUri(char uri[],char hostname[],char path[],char port[]);void build_http(char *server_http,char *hostname,char*path,char* port,rio_t *clientrio);void* thread(void *vargp);void initCache();void PreRead(int index);void afterRead(int index);void preWrite(int index);void afterWrite(int index);int findCache(char *url);void updateLRU(int index);int findSuitCache();void writeCacheContent(char *url,char* buf);//dongfanker 端口号50712//这是文件的cache单元数据结构typedef struct &#123;    char content[MAX_OBJECT_SIZE];    char url[MAXLINE];    int time;    int isEmpty;    int readCount;    int writeCount;    sem_t mutex;    sem_t w;&#125;cacheunit;//cache由10个cache的数据单元构成typedef struct &#123;    cacheunit cacheUnit[CACHE_NUM];&#125;Cache;Cache cache;//记录更新cache单元的次数int allTime=0;//定义用作消除竞争的flagsem_t flag;//首先获得端口号，用open_listenfd函数打开对套接子的监听之后，就无线循环，处理连接请求，执行请求，关闭链接它的另一端int main(int argc,char **argv)&#123;    int listenfd,*connfd;    char hostname[MAXLINE],port[MAXLINE];    socklen_t clientlen;    struct  sockaddr_storage clientaddr;    pthread_t tid;    Signal(SIGPIPE, SIG_IGN);    Sem_init(&amp;flag,0,1);    // the cmd parameters fail    if (argc!=2)&#123;        fprintf(stderr, &quot;usage: %s &lt;port&gt;\n&quot;,argv[0]);        exit(1);    &#125;    initCache();    listenfd= open_listenfd(argv[1]);    while (1)    &#123;        clientlen=sizeof(clientaddr);        connfd=malloc(sizeof(int));    //建立之后用于多线程的        *connfd=Accept(listenfd,(SA*)&amp;clientaddr,&amp;clientlen);        Getnameinfo((SA*)&amp;clientaddr,clientlen,hostname,MAXLINE,                    port,MAXLINE,0);        printf(&quot;Accepted connection from (%s , %s)\n&quot;,hostname,port);        Pthread_create(&amp;tid,NULL,thread,(void*)connfd);    &#125;&#125;//thread函数是在main函数中用作创建和处理线程的函数void *thread(void *vargo)&#123;    int connfd = *((int *)vargo);    Pthread_detach(pthread_self());    free(vargo);    doit(connfd);    Close(connfd);    return NULL;&#125;//do it函数是thread函数中的处理函数void doit(int connfd)&#123;    int serverFd;    rio_t clientrio,serverrio;    char server_http[MAXLINE],buf[MAXLINE],method[MAXLINE],path[MAXLINE];    char port[MAXLINE],uri[MAXLINE],version[MAXLINE],hostname[MAXLINE];    // P(&amp;flag);    //     allTime+=1;    // V(&amp;flag);    //首先获取一个request链接    rio_readinitb(&amp;clientrio,connfd);    rio_readlineb(&amp;clientrio,buf,MAXLINE);    sscanf(buf,&quot;%s %s %s&quot;,method,uri,version);    //对请求行进行处理，如果请求的方法不是GET的话，就告诉它我没有实现对这个方法的处理。    if (strcasecmp(method,&quot;GET&quot;))&#123;        printf(&quot;Proxy does not implement this method&quot;);        return;    &#125;    int cacheIndex;    if ((cacheIndex=findCache(uri))&gt;0)    &#123;        PreRead(cacheIndex);        rio_writen(connfd,cache.cacheUnit[cacheIndex].content,            strlen(cache.cacheUnit[cacheIndex].content));        printf(&quot;the proxy has received %lu bytes\n&quot;,            strlen(cache.cacheUnit[cacheIndex].content));        afterRead(cacheIndex);        updateLRU(cacheIndex);    &#125;    //然后就对uri进行解析，获得服务器主机名、文件地址以及端口浩    parseUri(uri,hostname,path,port);    //构建新的请求头    build_http(server_http,hostname,path,port,&amp;clientrio);    //与服务器端进行链接    serverFd=open_clientfd(hostname,port);    if (serverFd&lt;0)&#123;        printf(&quot;connection failed\n&quot;);        return;    &#125;    rio_readinitb(&amp;serverrio,serverFd);    //将请求头写入传送给服务器    rio_writen(serverFd,server_http,strlen(server_http));    size_t len;    size_t allCount=0;    char cacheBuf[MAX_OBJECT_SIZE];    //从服务器拿到消息，发回给客户端    while ((len=rio_readlineb(&amp;serverrio,buf,MAXLINE))!=0)    &#123;        allCount+=len;        if (allCount&lt;MAX_OBJECT_SIZE)            strcat(cacheBuf,buf);        rio_writen(connfd,buf,len);    &#125;    printf(&quot;the proxy has received %lu bytes\n&quot;,allCount);    Close(serverFd);    //当字节数低于    if (allCount&lt;MAX_OBJECT_SIZE)        writeCacheContent(uri,cacheBuf);&#125;//利用LRU（最近使用）的原则找到合适的Cache来用于写int findSuitCache()&#123;    int i,result=-1,minTime=0x7fffffff;    for (i=0;i&lt;CACHE_NUM;++i)&#123;        PreRead(i);        if (cache.cacheUnit[i].isEmpty)&#123;            result=i;        &#125;        afterRead(i);        if (result==i)            break;    &#125;    if (result!=-1)        return result;    for (i=0;i&lt;CACHE_NUM;++i)&#123;        PreRead(i);        if (cache.cacheUnit[i].time&lt;minTime)&#123;            minTime=cache.cacheUnit[i].time;            result=i;        &#125;        afterRead(i);    &#125;    return result;&#125;//这是do it里面的写cache的操作，用来调用上面定义的找到合适的cache1的findSuitCache函数，找到Cache来进行书写void writeCacheContent(char *url,char* buf)&#123;    int index = findSuitCache();    preWrite(index);    strcpy(cache.cacheUnit[index].content,buf);    strcpy(cache.cacheUnit[index].url,url);    cache.cacheUnit[index].isEmpty=0;    afterWrite(index);    updateLRU(index);&#125;/*此处构建新的请求头，Host、User-Agent、Connection、Proxy-Connection  等key的value部分修改为指定的信息，其他的保持不变*/void build_http(char *server_http,char *hostname,char*path,char* port,rio_t *clientrio)&#123;    char requestLine[MAXLINE],buf[MAXLINE];    char host_hdr[MAXLINE],other_hdr[MAXLINE];    //获得请求服务的正确字符串    sprintf(requestLine,&quot;GET %s HTTP/1.0\r\n&quot;,path);    while (rio_readlineb(clientrio,buf,MAXLINE)&gt;0)    &#123;        int type = getType(buf);        if (type==EOF_TYPE)            break;        else if (type==HOST_TYPE)&#123;            strcpy(host_hdr,buf);        &#125;        else&#123;            strcat(other_hdr,buf);        &#125;    &#125;    if (strlen(host_hdr)==0)        sprintf(host_hdr,&quot;Host: %s\r\n&quot;,hostname);    sprintf(server_http,&quot;%s%s%s%s%s%s\r\n&quot;,            requestLine,            host_hdr,            connect_hdr,            proxy_hdr,            user_agent_hdr,            other_hdr);    return;&#125;//这个是在build_http函数中进行字符串比较的getType函数int getType(char *buf)&#123;    if(strcmp(buf,&quot;\r\n&quot;)==0)        return EOF_TYPE;    else if (!strncasecmp(buf,host_key,strlen(host_key)))        return HOST_TYPE;    else if (strncasecmp(buf,connection_key,strlen(connection_key))             &amp;&amp;strncasecmp(buf,proxy_connection_key,strlen(proxy_connection_key))             &amp;&amp;strncasecmp(buf,user_agent_key,strlen(user_agent_key)))        return OTHER_TYPE;    return 0;&#125;//这是doit函数中对于uri的解析void parseUri(char uri[],char hostname[],char path[],char port[])&#123;    //从URI中获取服务器名字    int i=0;    char* hostnamePos=strstr(uri,&quot;//&quot;);    if (hostnamePos!=NULL)        hostnamePos+=2;    else        hostnamePos=uri;    strcpy(hostname,hostnamePos);    int len=strlen(hostname);    for (i=0;i&lt;len;++i)&#123;        if (hostname[i]==&#39;/&#39;||hostname[i]==&#39;:&#39;)&#123;            hostname[i]=&#39;\0&#39;;            break;        &#125;    &#125;    //从uri中获取端口号    char* portPos=strchr(hostnamePos,&#39;:&#39;);    if (portPos!=NULL)&#123;        strcpy(port,portPos+1);        len=strlen(port);        for (i=0;i&lt;len;++i)&#123;            if (!isdigit(port[i]))&#123;                port[i]=&#39;\0&#39;;                break;            &#125;        &#125;    &#125;    else&#123;        port[0]=&#39;8&#39;;port[1]=&#39;0&#39;;port[2]=&#39;\0&#39;;    &#125;    //从uri中获取路径    char *pathPos=strstr(uri,&quot;//&quot;);    if (pathPos!=NULL)        pathPos+=2;    else        pathPos=uri;    pathPos=strchr(pathPos,&#39;/&#39;);    strcpy(path,pathPos);    char *endpos = strchr(path,&#39;:&#39;);    if (endpos!=NULL)&#123;        (*endpos)=&#39;\0&#39;;    &#125;    printf(&quot;hostname:%s\npath:%s\nport:%s\n&quot;,hostname,path,port);    return;&#125;//这是main函数中用来初始化Cache函数void initCache()&#123;    int i = 0;    for (i = 0; i &lt; 10; ++i)    &#123;        cache.cacheUnit[i].isEmpty=1;        cache.cacheUnit[i].time=0;        Sem_init(&amp;cache.cacheUnit[i].mutex,0,1);        Sem_init(&amp;cache.cacheUnit[i].w,0,1);        cache.cacheUnit[i].readCount=0;        cache.cacheUnit[i].writeCount=0;    &#125;&#125;//关键问题，使用信号量来限制程序的执行顺序。计数信号量具备两种操作动作，称为 V（又称signal()）与 P（wait()）// 一下四个函数用于Cache的加锁与解锁// 用以解决竞争问题/*运行 P，信号量 S 的值将被减少。倘若进程企图进入临界区块的，需要先运行 P。当信号量 S 减为负值时，进程会被挡住，不能继续；当信号量S不为负值时，进程可以获准进入临界区块  */void PreRead(int index)&#123;    P(&amp;cache.cacheUnit[index].mutex);    cache.cacheUnit[index].readCount++;    if (cache.cacheUnit[index].readCount==1)        P(&amp;cache.cacheUnit[index].w);    V(&amp;cache.cacheUnit[index].mutex);&#125;//运行 V，信号量 S 的值会被增加。倘若进程想要结束离开临界区块，将会运行 V。当信号量 S 不为负值时，先前被挡住的其他进程，将可获准进入临界区块。void afterRead(int index)&#123;    P(&amp;cache.cacheUnit[index].mutex);    cache.cacheUnit[index].readCount--;    if (cache.cacheUnit[index].readCount==0)        V(&amp;cache.cacheUnit[index].w);    V(&amp;cache.cacheUnit[index].mutex);&#125;void preWrite(int index)&#123;    P(&amp;cache.cacheUnit[index].w);&#125;void afterWrite(int index)&#123;    V(&amp;cache.cacheUnit[index].w);&#125;int findCache(char *url)&#123;    int i,result=-1;    for (i=0;i&lt;CACHE_NUM;++i)&#123;        PreRead(i);        if ((cache.cacheUnit[i].isEmpty==0)&amp;&amp;            strcmp(cache.cacheUnit[i].url,url)==0)            result=i;        afterRead(i);    &#125;    return result;&#125;//update the read/write cache&#39;s visit time void updateLRU(int index)&#123;    preWrite(index);    cache.cacheUnit[index].time=allTime;    afterWrite(index);&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> ICS lab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ICS </tag>
            
            <tag> CS APP </tag>
            
            <tag> proxy </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
