<!DOCTYPE html><html class="appearance-auto" lang="en"><head><meta name="google-site-verification" content="EnW3iE5uXnkCt08dH5N1p2UztpHHWUslmyE_mIIGaac"><meta name="baidu-site-verification" content="code-EtTckMomHC"><meta charset="UTF-8"><title>Tensorflow 基本概念</title><meta name="description" content="精诚致志，求仁存心"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/favicon.png"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/post.css"><link rel="stylesheet" href="/style/themes/highlight-theme-light.css"><script src="/js/highlight.pack.js"></script><meta name="description" content="计算图Tensorflow程序的计算可分为两个阶段，在第一个阶段定义所有计算图中的计算，第二阶段为执行计算。下面定义一个计算，生成计算图
import tensorflow as tf
a = tf.constant([1.0, 2.0], name=&amp;quot;a&amp;quot;)
b = tf.constant([2.0, 3.0], name=&amp;quot;b&amp;quot;)
result = a + b 
print(tf.get_default_graph())
print(a.graph)
print(b.graph)

result: 均属于同一个计算图
&amp;lt;tensorflow.python.framework.ops.Graph object at 0x0000012C137DAD68&amp;gt;.."><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.0.0"><link rel="alternate" href="/atom.xml" title="Yanjian Zhang's Blog" type="application/atom+xml">
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">Yanjian Zhang's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><div class="is-full-height" id="postTopic"><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">Tensorflow 基本概念</p><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">Click back to the top</p></div></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></header><main><main class="container is-max-widescreen content section post-page pt-4 px-4"><div class="columns is-flex-desktop is-justify-content-center is-flex-direction-row-reverse"><div class="column is-3 is-hidden-mobile"><ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E5%9B%BE"><span class="toc-number">1.</span> <span class="toc-text">计算图</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BC%A0%E9%87%8F"><span class="toc-number">2.</span> <span class="toc-text">张量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%9A%E8%AF%9D"><span class="toc-number">3.</span> <span class="toc-text">会话</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%A4%BA%E4%BE%8B"><span class="toc-number">4.</span> <span class="toc-text">前向传播示例</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#placeholder"><span class="toc-number">5.</span> <span class="toc-text">placeholder</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B7%BB%E5%8A%A0%E5%B1%82"><span class="toc-number">6.</span> <span class="toc-text">添加层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE"><span class="toc-number">7.</span> <span class="toc-text">导入数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA%E7%BD%91%E7%BB%9C"><span class="toc-number">8.</span> <span class="toc-text">构建网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#GPU-support"><span class="toc-number">9.</span> <span class="toc-text">GPU support</span></a></li></ol></div><div class="column is-9"><header class="my-4"><a href="/tags/tensorflow"><i class="tag post-item-tag">tensorflow</i></a></header><h1 class="mt-0 mb-1 is-family-serif" id="postTitle">Tensorflow 基本概念</h1><time class="has-text-grey" datetime="2018-11-07T23:44:02.000Z">2018-11-08</time><article class="mt-2 post-content"><h4 id="计算图"><a href="#计算图" class="headerlink" title="计算图"></a>计算图</h4><p>Tensorflow程序的计算可分为两个阶段，在第一个阶段定义所有计算图中的计算，第二阶段为执行计算。<br>下面定义一个计算，生成计算图</p>
<pre><code class="lang-python">import tensorflow as tf
a = tf.constant([1.0, 2.0], name=&quot;a&quot;)
b = tf.constant([2.0, 3.0], name=&quot;b&quot;)
result = a + b 
print(tf.get_default_graph())
print(a.graph)
print(b.graph)
</code></pre>
<p>result: 均属于同一个计算图</p>
<pre><code>&lt;tensorflow.python.framework.ops.Graph object at 0x0000012C137DAD68&gt;
&lt;tensorflow.python.framework.ops.Graph object at 0x0000012C137DAD68&gt;
&lt;tensorflow.python.framework.ops.Graph object at 0x0000012C137DAD68&gt;
</code></pre><p>还可以通过tf.Graph函数来生成新的计算图，代码如下，注意注释的部分已经被淘汰</p>
<pre><code class="lang-python">import tensorflow as tf
g1 = tf.Graph()
with g1.as_default():
    v1 = tf.get_variable(
        # &quot;v&quot;, initializer=tf.zeros_initializer(shape[1])
        &quot;v1&quot;, shape=[4], initializer=tf.zeros_initializer()
    )
    v2 = tf.get_variable(
        &quot;v2&quot;, shape=[4], initializer=tf.ones_initializer()
    )

with tf.Session(graph=g1) as sess:
    # # tf.initialize_all_variables().run()
    sess.run(tf.global_variables_initializer())
    with tf.variable_scope(&quot;&quot;, reuse=True):
        print(sess.run(tf.get_variable(&quot;v1&quot;)))
        print(sess.run(tf.get_variable(&quot;v2&quot;)))
</code></pre>
<p>result</p>
<pre><code>[ 0.  0.  0.  0.]
[ 1.  1.  1.  1.]
</code></pre><h4 id="张量"><a href="#张量" class="headerlink" title="张量"></a>张量</h4><p>下面介绍张量</p>
<pre><code class="lang-python">import tensorflow as tf
a = tf.constant([1, 2], name=&quot;a&quot;, dtype=tf.float32)
b = tf.constant([2.0, 3.0], name=&quot;b&quot;)
result1 = a + b
# 此时还没有结果
print(result1)
result2 = tf.add(a, b, name=&quot;add&quot;)
# 此时才会有结果
print(result2)
</code></pre>
<p>result：可以看见在result1中默认会命名“+”为add，后面相同的名字TensorFlow会进行修改</p>
<pre><code>Tensor(&quot;add:0&quot;, shape=(2,), dtype=float32)
Tensor(&quot;add_1:0&quot;, shape=(2,), dtype=float32)
</code></pre><h4 id="会话"><a href="#会话" class="headerlink" title="会话"></a>会话</h4><p>下面是会话<br>创建会话可以通过两种模式创建，一种是明确创建和关闭会话的函数</p>
<pre><code class="lang-python">sess = tf.Session()
sess.run(...)
sess.close()
</code></pre>
<p>另一种就直接通过上下文管理器来管理会话，使用with</p>
<pre><code class="lang-python">with tf.Session() as sess:
    sess.run(...)
</code></pre>
<p>配置GPU的使用,其中allow_soft_placement会使得某些不被GPU支持的运算放入CPU中，而log_device_placement选择是否打印日记，可以记录那个节点被安排到哪个设备方便调试，而在生产环境中设为False,可以减少日志量</p>
<pre><code>config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)
with tf.Session(graph=g1, config=config) as sess:
    ......
</code></pre><h4 id="前向传播示例"><a href="#前向传播示例" class="headerlink" title="前向传播示例"></a>前向传播示例</h4><p>下面是一个简单的神经网络的前向传播的过程,注意x为列向量，有两个[]</p>
<pre><code class="lang-python">import tensorflow as tf
w1 = tf.Variable(tf.random_normal([2, 3], stddev=1, seed=1))
w2 = tf.Variable(tf.random_normal([3, 1], stddev=1, seed=1))
print(w1, w2)
x = tf.constant([[0.7, 0.9]])
a = tf.matmul(x, w1)
y = tf.matmul(a, w2) #此处是product
# 也可以是 with tf.Session as sess:
sess = tf.Session()
# 此处需要进行初始化
sess.run(tf.global_variables_initializer()) # 获得所想要得到的运算结果
print(sess.run(y)) #对product进行运算

sess.close()
</code></pre>
<p>result</p>
<pre><code>[[ 3.95757794]]
</code></pre><h4 id="placeholder"><a href="#placeholder" class="headerlink" title="placeholder"></a>placeholder</h4><pre><code class="lang-python">input1 = tf.placeholder(tf.float32)
</code></pre>
<p>之后需要feed才能run</p>
<h4 id="添加层"><a href="#添加层" class="headerlink" title="添加层"></a>添加层</h4><pre><code class="lang-python">def add_layer(inputs,in_size,out_size,activation_fun = None):
    weight = tf.VAriable(tf.random_normal([in_size,out_size]))
    biase = ...
    if activation != None:
        return activation(input*weight+biase)
</code></pre>
<h4 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h4><pre><code class="lang-python"># None 表示任意数量
xs = tf.placeholder(tf.float32,[None, 784]) # 28*28
ys = tf.placeholder(tf.float32,[None, 10]) # 10
</code></pre>
<h4 id="构建网络"><a href="#构建网络" class="headerlink" title="构建网络"></a>构建网络</h4><pre><code>l1 = add_layer(xs, 1, 10 activation = tf.nn.relu)
loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys-prediction),reduction_indices = [1]))
train_step = tf.train.Gradient...
sess.run(...)
</code></pre><h4 id="GPU-support"><a href="#GPU-support" class="headerlink" title="GPU support"></a>GPU support</h4><pre><code class="lang-python">config = tf.ConfigProto()
config.gpu_options.allow_growth = True # 按需分配，不全部占用

for d in [&quot;/device:GPU:2&quot;,&quot;/device:GPU:3&quot;] #使用多块GPU
    with tf.device(d):
</code></pre>
</article><section class="jump-container is-flex is-justify-content-space-between my-6"><!-- em is empty placeholder--><a class="button is-default" href="/tensorboard/" title="Tensorboard的使用"><i class="iconfont icon-prev mr-2 has-text-grey"></i><span class="has-text-weight-semibold">Previous: Tensorboard的使用</span></a><a class="button is-default" href="/cookbookString/" title="字符串和文本处理"><span class="has-text-weight-semibold">Next: 字符串和文本处理</span><i class="iconfont icon-next ml-2 has-text-grey"></i></a></section><article class="mt-6 comment-container"><script async repo="Haojen/Claudia-theme-blog" src="https://utteranc.es/client.js" issue-term="pathname" theme="preferred-color-scheme"></script></article></div></div></main></main><script src="/js/post.js"></script></body></html>